{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invasive Species Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W207-3 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors: Stanimir Vichev, James Nguyen, Melwin Poovakottu, Jonah Smith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date: 08/21/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "Our team took part in the Invasive Species competition in Kaggle, trying to develop, configure and fit the best machine learning algorithm for binary classification of images. We tried several algorithms, such as Linear Support Vector Machines (SVM), Logistic Regression (LR), single-layer neural networks (single-NN), and Convolutional Neural Networks (CNN), as well as a variety of data augmentation methods to generate more data. In this report we start by describing the competition, followed by exploring the data set and looking at the data augmentation techniques employed. We then describe the implementation and performance of our initial attempts to use simpler algorithms, such as Linear SVM and LR. This is followed by a discussion of our main approach of using a CNN, the theory behind it, how it was implemented, and the resulting performance. We finish by discussing our Kaggle submission results and future improvements\n",
    "\n",
    "### Competition:\n",
    "\n",
    "Tangles of kudzu overwhelm trees in Georgia while cane toads threaten habitats in over a dozen countries worldwide. These are just two invasive species of many which can have damaging effects on the environment, the economy, and even human health. Despite widespread impact, efforts to track the location and spread of invasive species are so costly that theyâ€™re difficult to undertake at scale.\n",
    "\n",
    "Currently, ecosystem and plant distribution monitoring depends on expert knowledge. Trained scientists visit designated areas and take note of the species inhabiting them. Using such a highly qualified workforce is expensive, time inefficient, and insufficient since humans cannot cover large areas when sampling.\n",
    "Because scientists cannot sample a large quantity of areas, some machine learning algorithms are used in order to predict the presence or absence of invasive species in areas that have not been sampled. The accuracy of this approach is far from optimal, but still contributes to approaches to solving ecological problems.\n",
    "\n",
    "In this playground competition, Kagglers are challenged to develop algorithms to more accurately identify whether images of forests and foliage contain invasive hydrangea or not. Techniques from computer vision alongside other current technologies like aerial imaging can make invasive species monitoring cheaper, faster, and more reliable.\n",
    "\n",
    "The data set contains pictures taken in a Brazilian national forest. In some of the pictures there is Hydrangea, a beautiful invasive species original of Asia. Based on the training pictures and the labels provided, the participant should predict the presence of the invasive species in the testing set of pictures.\n",
    "\n",
    "More details at: https://www.kaggle.com/c/invasive-species-monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import random_seed\n",
    "\n",
    "import numpy as np\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data\n",
    "\n",
    "We had around 2k images for training and 1k images for testing, the latter being unlabelled data used for our Kaggle submissions. Each image had colour and dimensions (866,1154,3), meaning that we were faced with the Curse of Dimensionality: having a lot of features and not enough data to cover the sample space. Additionally, the images were large and would take up a lot of memory, so we loaded them in batches for processing and training. The below classes and functions are used to perform data loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO change to train_data/train_labels.csv\n",
    "data_path = \"train_data/\"\n",
    "# data_path = \"D:/MIDS/W207_3 Machine Learning/project_data/\"\n",
    "train_labels = pd.read_csv(data_path +\"train_labels.csv\")['invasive'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = data_path\n",
    "test_data_path = data_path +\"test/\"\n",
    "# train_data_path = data_path + \"train/\"\n",
    "# test_data_path = data_path + \"test/\"\n",
    "def load_images(indices):\n",
    "    images= np.zeros(shape=(len(indices), 866, 1154, 3), dtype=np.uint8)\n",
    "    for p, i in enumerate(indices):\n",
    "        im = Image.open(train_data_path+str(i+1)+\".jpg\")\n",
    "    # open image file and store in variable `im`, then\n",
    "        images[p] = np.array(im)\n",
    "    images = images.astype(np.float32)\n",
    "    images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "    return images\n",
    "\n",
    "def load_test_images(indices):\n",
    "    images= np.zeros(shape=(len(indices), 866, 1154, 3), dtype=np.uint8)\n",
    "    for p, i in enumerate(indices):\n",
    "        im = Image.open(test_data_path+str(i+1)+\".jpg\")\n",
    "    # open image file and store in variable `im`, then\n",
    "        newimg= np.array(im).reshape(866,1154,3)\n",
    "    \n",
    "        images[p] = newimg\n",
    "    images = images.astype(np.float32)\n",
    "    images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "    return images\n",
    "\n",
    "def load_images_flat(indices, labels, path = data_path, seq = None):\n",
    "    # resize to (400,300 from now and flatten array)\n",
    "    # images= np.zeros(shape=(len(indices), 1440000), dtype=np.uint8)\n",
    "    images= np.zeros(shape=(len(indices), 2998092), dtype=np.uint8)\n",
    "    new_labels = np.zeros(shape = (labels.shape[0],))\n",
    "    if seq:\n",
    "        images= np.zeros(shape=(len(indices)*2, 2998092), dtype=np.uint8)\n",
    "        new_labels = np.zeros(shape = (labels.shape[0]*2,))\n",
    "    index = 0\n",
    "    for p, i in enumerate(indices):\n",
    "        im = Image.open(path+str(i+1)+\".jpg\")\n",
    "        # doing an extra resize\n",
    "        # arr = np.array(im.resize((800,600))).reshape(1,1440000)\n",
    "        vanilla_arr = np.array(im).reshape(1,2998092)\n",
    "        images[index] = vanilla_arr\n",
    "        new_labels[index]=labels[p]\n",
    "        if seq:\n",
    "            aug_arr = seq.augment_images([np.array(im)])[0].reshape(1,2998092)\n",
    "            index +=1\n",
    "            images[index] = aug_arr\n",
    "            new_labels[index]=labels[p]\n",
    "        index +=1\n",
    "    images = images.astype(np.float32)\n",
    "    images = np.multiply(images, 1.0 / 255.0)\n",
    "    return images, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Image, classified as 1\n",
      "Example Image, classified as 0\n"
     ]
    }
   ],
   "source": [
    "im_i = 3\n",
    "print(\"Example Image, classified as \"+str(train_labels[im_i-1]))\n",
    "im = Image.open(train_data_path+str(im_i)+\".jpg\")\n",
    "im.thumbnail([300,400])\n",
    "im.save(\"example_invasive.png\")\n",
    "# im.show()\n",
    "\n",
    "im_i = 1\n",
    "print(\"Example Image, classified as \"+str(train_labels[im_i-1]))\n",
    "im = Image.open(train_data_path+str(im_i)+\".jpg\")\n",
    "im.thumbnail([300,400])\n",
    "im.save(\"example_no_invasive.png\")\n",
    "# im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of an image with the invasive species:\n",
    "![example_invasive](example_invasive.png)\n",
    "\n",
    "Example of an image without the invasive species:\n",
    "![example_no_invasive](example_no_invasive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is created to load the images and to manage lazy loading of images in different epoches. Lazy loading is important because of limited GPU/CPU memory resources. The loading also shuffles images for every new epoch to maximize training efficiency. This version of the class is without image data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "\n",
    "  def __init__(self,\n",
    "               image_indices,\n",
    "               labels,\n",
    "               seed=None):\n",
    "    seed1, seed2 = random_seed.get_seed(seed)\n",
    "    # If op level seed is not set, use whatever graph level seed is returned\n",
    "    np.random.seed(seed1 if seed is None else seed2)\n",
    "    self._num_examples = len(image_indices)\n",
    "    self._image_indices = image_indices\n",
    "    self._labels = labels\n",
    "    self._epochs_completed = 0\n",
    "    self._index_in_epoch = 0\n",
    "\n",
    "  @property\n",
    "  def image_indices(self):\n",
    "    return self._image_indices\n",
    "\n",
    "  @property\n",
    "  def labels(self):\n",
    "    return self._labels\n",
    "\n",
    "  @property\n",
    "  def num_examples(self):\n",
    "    return self._num_examples\n",
    "\n",
    "  @property\n",
    "  def epochs_completed(self):\n",
    "    return self._epochs_completed\n",
    "\n",
    "  def load_images(indices):\n",
    "\n",
    "        images= np.zeros(shape=(len(indices), 866, 1154, 3), dtype=np.uint8)\n",
    "        for i in indices:\n",
    "            im = Image.open(\"train_data/\"+str(i+1)+\".jpg\")\n",
    "        # open image file and store in variable `im`, then\n",
    "            images[i] = np.array(im)\n",
    "        images = images.astype(np.float32)\n",
    "        images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "        return images\n",
    "\n",
    "  def next_batch(self, batch_size, shuffle=True):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = self._index_in_epoch\n",
    "    # Shuffle for the first epoch\n",
    "    if self._epochs_completed == 0 and start == 0 and shuffle:\n",
    "      perm0 = np.arange(self._num_examples)\n",
    "      np.random.shuffle(perm0)\n",
    "      self._image_indices = self.image_indices[perm0]\n",
    "      self._labels = self.labels[perm0]\n",
    "    # Go to the next epoch\n",
    "    if start + batch_size > self._num_examples:\n",
    "      # Finished epoch\n",
    "      self._epochs_completed += 1\n",
    "      # Get the rest examples in this epoch\n",
    "      rest_num_examples = self._num_examples - start\n",
    "      images_rest_part = self._image_indices[start:self._num_examples]\n",
    "      labels_rest_part = self._image_indices[start:self._num_examples]\n",
    "      # Shuffle the data\n",
    "      if shuffle:\n",
    "        perm = np.arange(self._num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        self._image_indices = self.image_indices[perm]\n",
    "        self._labels = self.labels[perm]\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      self._index_in_epoch = batch_size - rest_num_examples\n",
    "      end = self._index_in_epoch\n",
    "      images_new_part = self._image_indices[start:end]\n",
    "      labels_new_part = self._labels[start:end]\n",
    "      return load_images(np.concatenate((images_rest_part, images_new_part), axis =0)), np.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "    else:\n",
    "      self._index_in_epoch += batch_size\n",
    "      end = self._index_in_epoch\n",
    "      return load_images(self._image_indices[start:end]), self._labels[start:end]\n",
    "  def next_pred_batch(self, batch_size):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = self._index_in_epoch\n",
    "    if start + batch_size > self._num_examples:\n",
    "      rest_num_examples = self._num_examples - start\n",
    "      images_rest_part = self._image_indices[start:self._num_examples]\n",
    "      return load_test_images(images_rest_part)\n",
    "    else:\n",
    "      self._index_in_epoch += batch_size\n",
    "      end = self._index_in_epoch\n",
    "      return load_test_images(self._image_indices[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is created to load the images and to manage lazy loading of images in different epoches. Lazy loading is important because of limited GPU/CPU memory resources. The loading also shuffles images for every new epoch to maximize training efficiency. We also include data augmentation procedure to generate more images by apply techques such as blurring or rotation. The augmented data is combined with original data to produce new datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataAugSet(object):\n",
    "\n",
    "  def __init__(self,\n",
    "               image_indices,\n",
    "               labels,\n",
    "               seed=None):\n",
    "    seed1, seed2 = random_seed.get_seed(seed)\n",
    "    # If op level seed is not set, use whatever graph level seed is returned\n",
    "    np.random.seed(seed1 if seed is None else seed2)\n",
    "    self._num_examples = len(image_indices)\n",
    "    self._image_indices = image_indices\n",
    "    self._labels = labels\n",
    "    self._epochs_completed = 0\n",
    "    self._index_in_epoch = 0\n",
    "\n",
    "  @property\n",
    "  def image_indices(self):\n",
    "    return self._image_indices\n",
    "\n",
    "  @property\n",
    "  def labels(self):\n",
    "    return self._labels\n",
    "\n",
    "  @property\n",
    "  def num_examples(self):\n",
    "    return self._num_examples\n",
    "\n",
    "  @property\n",
    "  def epochs_completed(self):\n",
    "    return self._epochs_completed\n",
    "\n",
    "  def load_images(self, indices):\n",
    "        images= np.zeros(shape=(len(indices), 866, 1154, 3), dtype=np.uint8)\n",
    "        for p, i in enumerate(indices):\n",
    "            im = Image.open(\"train_data/\"+str(i+1)+\".jpg\")\n",
    "        # open image file and store in variable `im`, then\n",
    "            images[p] = np.array(im)\n",
    "        images = images.astype(np.float32)\n",
    "        images = np.multiply(images, 1.0 / 255.0)\n",
    "#         sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "        seq = iaa.Sequential([\n",
    "#             iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "#             iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "            iaa.GaussianBlur(sigma=(1, 4.0)), # blur images with a sigma of 0 to 3.0\n",
    "#             sometimes(iaa.Affine( rotate=(-90, 90)))\n",
    "\n",
    "        ])\n",
    "\n",
    "    \n",
    "        images_trans = seq.augment_images(images)\n",
    "        return np.concatenate((images, images_trans), axis =0)\n",
    "        return images\n",
    "  def load_ori_images(self, indices):\n",
    "        images= np.zeros(shape=(len(indices), 866, 1154, 3), dtype=np.uint8)\n",
    "        for p, i in enumerate(indices):\n",
    "            im = Image.open(\"train_data/\"+str(i+1)+\".jpg\")\n",
    "        # open image file and store in variable `im`, then\n",
    "            images[p] = np.array(im)\n",
    "        images = images.astype(np.float32)\n",
    "        images = np.multiply(images, 1.0 / 255.0)\n",
    "        return images\n",
    "  def load_test_images(self, indices):\n",
    "    images= np.zeros(shape=(len(indices), 866, 1154, 3), dtype=np.uint8)\n",
    "    for p, i in enumerate(indices):\n",
    "        im = Image.open(\"test_data/test/\"+str(i+1)+\".jpg\")\n",
    "    # open image file and store in variable `im`, then\n",
    "        newimg= np.array(im).reshape(866,1154,3)\n",
    "\n",
    "        images[p] = newimg\n",
    "    images = images.astype(np.float32)\n",
    "    images = np.multiply(images, 1.0 / 255.0)    \n",
    "    return images\n",
    "  def next_batch(self, batch_size, shuffle=True):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = self._index_in_epoch\n",
    "    # Shuffle for the first epoch\n",
    "    if self._epochs_completed == 0 and start == 0 and shuffle:\n",
    "      perm0 = np.arange(self._num_examples)\n",
    "      np.random.shuffle(perm0)\n",
    "      self._image_indices = self.image_indices[perm0]\n",
    "      self._labels = self.labels[perm0]\n",
    "    # Go to the next epoch\n",
    "    if start + batch_size > self._num_examples:\n",
    "      # Finished epoch\n",
    "#       print(\"Finish epoch\")\n",
    "\n",
    "      self._epochs_completed += 1\n",
    "      # Get the rest examples in this epoch\n",
    "      rest_num_examples = self._num_examples - start\n",
    "      images_rest_part = self._image_indices[start:self._num_examples]\n",
    "      labels_rest_part = self._image_indices[start:self._num_examples]\n",
    "      # Shuffle the data\n",
    "      if shuffle:\n",
    "        perm = np.arange(self._num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        self._image_indices = self.image_indices[perm]\n",
    "        self._labels = self.labels[perm]\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      self._index_in_epoch = batch_size - rest_num_examples\n",
    "      end = self._index_in_epoch\n",
    "      images_new_part = self._image_indices[start:end]\n",
    "      labels_new_part = self._labels[start:end]\n",
    "      labels = np.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "      labels = np.concatenate((labels, labels), axis=0)\n",
    "      return self.load_images(np.concatenate((images_rest_part, images_new_part), axis =0)),labels\n",
    "    else:\n",
    "      self._index_in_epoch += batch_size\n",
    "      end = self._index_in_epoch\n",
    "      labels = self._labels[start:end]\n",
    "      labels = np.concatenate((labels, labels), axis=0)\n",
    "      return self.load_images(self._image_indices[start:end]), labels\n",
    "  def next_pred_batch(self, batch_size):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = self._index_in_epoch\n",
    "    if start + batch_size > self._num_examples:\n",
    "      rest_num_examples = self._num_examples - start\n",
    "      images_rest_part = self._image_indices[start:self._num_examples]\n",
    "      return self.load_test_images(images_rest_part)\n",
    "    else:\n",
    "      self._index_in_epoch += batch_size\n",
    "      end = self._index_in_epoch\n",
    "      return self.load_test_images(self._image_indices[start:end])\n",
    "#   def next_val_batch(self, batch_size, shuffle=True):\n",
    "#     \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "#     start = self._index_in_epoch\n",
    "#     # Shuffle for the first epoch\n",
    "#     if self._epochs_completed == 0 and start == 0 and shuffle:\n",
    "#       perm0 = np.arange(self._num_examples)\n",
    "#       np.random.shuffle(perm0)\n",
    "#       self._image_indices = self.image_indices[perm0]\n",
    "#       self._labels = self.labels[perm0]\n",
    "#     # Go to the next epoch\n",
    "#     if start + batch_size > self._num_examples:\n",
    "#       # Finished epoch\n",
    "#       print(\"Finish epoch\")\n",
    "#       self._epochs_completed += 1\n",
    "#       # Get the rest examples in this epoch\n",
    "#       rest_num_examples = self._num_examples - start\n",
    "#       images_rest_part = self._image_indices[start:self._num_examples]\n",
    "#       labels_rest_part = self._image_indices[start:self._num_examples]\n",
    "#       # Shuffle the data\n",
    "#       if shuffle:\n",
    "#         perm = np.arange(self._num_examples)\n",
    "#         np.random.shuffle(perm)\n",
    "#         self._image_indices = self.image_indices[perm]\n",
    "#         self._labels = self.labels[perm]\n",
    "#       # Start next epoch\n",
    "#       start = 0\n",
    "#       self._index_in_epoch = batch_size - rest_num_examples\n",
    "#       end = self._index_in_epoch\n",
    "#       images_new_part = self._image_indices[start:end]\n",
    "#       labels_new_part = self._labels[start:end]\n",
    "#       labels = np.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "#       return self.load_ori_images(np.concatenate((images_rest_part, images_new_part), axis =0)),labels\n",
    "#     else:\n",
    "#       self._index_in_epoch += batch_size\n",
    "#       end = self._index_in_epoch\n",
    "#       labels = self._labels[start:end]\n",
    "#       return self.load_ori_images(self._image_indices[start:end]), labels\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Attempts\n",
    "\n",
    "We used Logistic Regression and Linear SVM in order to get a baseline accuracy on our train and test dataset. First, LR was chosen as it is the precursor to Neural Networks and CNNs, which we would use eventually. Linear SVMs, on the other hand, are another powerful algorithm for fitting non-linear data, especially one with a large number of features. \n",
    "\n",
    "#### Logistic Regression\n",
    "\n",
    "we are using simple logistic regression in tensorflow to classify the images. We will convert each image to a one dimensional vector of length height X width X channels. We create two variables one for the feature weights another for the bias. We use cross entropy as the cost function and use gradient descent to find the minima.\n",
    "\n",
    "First, we use the DataSet class to prepare the data for loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading the Data\n",
    "train_size = 1840\n",
    "dev_size = 1840\n",
    "\n",
    "y_train = train_labels[:train_size]\n",
    "y_dev = train_labels[train_size:dev_size]\n",
    "train_data = DataSet(np.arange(0,train_size), y_train)\n",
    "test_data = DataSet(np.arange(train_size,len(train_labels)), y_dev)\n",
    "\n",
    "y_validation = train_labels[train_size:]\n",
    "validation_data = DataSet(np.arange(train_size,len(train_labels)), y_validation)\n",
    "y_train[1]\n",
    "\n",
    "y_train = train_labels[:1600]\n",
    "y_dev = train_labels[1600:]\n",
    "train_data = DataSet(np.arange(0,1600), y_train)\n",
    "test_data = DataSet(np.arange(1600,len(train_labels)), y_dev)\n",
    "\n",
    "X_val, y_val = validation_data.next_batch(80)\n",
    "#reshaping data, so that all pixel values for an image are on a single line\n",
    "X_val = X_val.reshape(X_val.shape[0],866*1154*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set up our Tensorflow graph and inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height = 866\n",
    "width = 1154\n",
    "channels = 3\n",
    "n_inputs = height * width\n",
    "\n",
    "n_outputs = 2\n",
    "# reset tf graph before run\n",
    "reset_graph()\n",
    "\n",
    "# set up the input tf tensors\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X_lgr = tf.placeholder(tf.float32, shape=[None, height* width* channels], name=\"X_lgr\")\n",
    "\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "    W = tf.Variable(tf.zeros([height* width* channels,2]))\n",
    "    b = tf.Variable(tf.zeros([2]))\n",
    "    \n",
    "with tf.name_scope(\"Logistic_regression\"):\n",
    "    #y_lgr =tf.transpose(tf.matmul(X_lgr,W) + b)\n",
    "    #y_lgr.eval()\n",
    "    y_lgr =tf.matmul(X_lgr,W) + b\n",
    "    #print(y_lgr.shape)\n",
    "    \n",
    "with tf.name_scope(\"train_lgr\"):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_lgr, labels=y)\n",
    "    loss_lgr = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "    training_lgr = optimizer.minimize(loss_lgr)\n",
    "\n",
    "with tf.name_scope(\"eval_logistiic\"):\n",
    "    correct_lgr = tf.nn.in_top_k(y_lgr, y, 1)\n",
    "    accuracy_lgr = tf.reduce_mean(tf.cast(correct_lgr, tf.float32))        \n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below classes are used to capture our model parameters when we manage to fit a new model. This is needed so that we could reload them later and run our predictions with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_params():\n",
    "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "def restore_model_params(model_params):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the tf tensors set, we can go on to fit our model. We will keep running until we stop making any progress on our loss function or when we reach 20 iterations. The train and test accuracy at each step are printed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train accuracy: 36.2500%, valid. accuracy: 38.7500%, valid. best loss: 35662.085938\n",
      "Epoch 1, train accuracy: 37.5000%, valid. accuracy: 42.5000%, valid. best loss: 8927.712891\n",
      "Epoch 2, train accuracy: 47.5000%, valid. accuracy: 45.0000%, valid. best loss: 8927.712891\n",
      "Epoch 3, train accuracy: 73.7500%, valid. accuracy: 68.7500%, valid. best loss: 8927.712891\n",
      "Epoch 4, train accuracy: 53.7500%, valid. accuracy: 46.2500%, valid. best loss: 8927.712891\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 80\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 5\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 10\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(train_data.num_examples // batch_size):\n",
    "            X_batch, y_batch = train_data.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape(X_batch.shape[0],height* width* channels)\n",
    "            sess.run(training_lgr, feed_dict={X_lgr: X_batch, y: y_batch, training: True})\n",
    "            if iteration % check_interval == 0:\n",
    "                loss_val = loss_lgr.eval(feed_dict={X_lgr: X_val, y: y_val})\n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "            #print( best_loss_val,\" \",loss_val)\n",
    "        acc_train = accuracy_lgr.eval(feed_dict={X_lgr: X_batch, y: y_batch})\n",
    "        acc_val = accuracy_lgr.eval(feed_dict={X_lgr: X_val,\n",
    "                                           y: y_val})\n",
    "        print(\"Epoch {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
    "                  epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "    save_path = saver.save(sess, \"./my_lr_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see below for a sample output:\n",
    "\n",
    "Epoch 0, train accuracy: 76.2500%, valid. accuracy: 63.7500%, valid. best loss: 24724.953125\n",
    "\n",
    "Epoch 1, train accuracy: 72.5000%, valid. accuracy: 70.0000%, valid. best loss: 10541.773438\n",
    "\n",
    "Epoch 2, train accuracy: 47.5000%, valid. accuracy: 47.5000%, valid. best loss: 10541.773438\n",
    "\n",
    "Epoch 3, train accuracy: 67.5000%, valid. accuracy: 62.5000%, valid. best loss: 10541.773438\n",
    "\n",
    "Epoch 4, train accuracy: 68.7500%, valid. accuracy: 65.0000%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 5, train accuracy: 78.7500%, valid. accuracy: 70.0000%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 6, train accuracy: 76.2500%, valid. accuracy: 62.5000%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 7, train accuracy: 61.2500%, valid. accuracy: 61.2500%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 8, train accuracy: 68.7500%, valid. accuracy: 63.7500%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 9, train accuracy: 62.5000%, valid. accuracy: 61.2500%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 10, train accuracy: 57.5000%, valid. accuracy: 62.5000%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 11, train accuracy: 67.5000%, valid. accuracy: 66.2500%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 12, train accuracy: 56.2500%, valid. accuracy: 63.7500%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 13, train accuracy: 61.2500%, valid. accuracy: 62.5000%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 14, train accuracy: 65.0000%, valid. accuracy: 65.0000%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 15, train accuracy: 80.0000%, valid. accuracy: 70.0000%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 16, train accuracy: 52.5000%, valid. accuracy: 56.2500%, valid. best loss: 10233.330078\n",
    "\n",
    "Epoch 17, train accuracy: 81.2500%, valid. accuracy: 71.2500%, valid. best loss: 10233.330078\n",
    "\n",
    "Early stopping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from our results that LR has strongly fluctuating training and testing accuracy, with the highest training accuracy being 81% and the highest test accuracy being 71%. This means that the algorithm is not complex enough and seems to be underfitting the data set, which could be down to the fact that LR represents only a single neuron in an NN, so it isn't complex enough to represent any nonlinear relationships correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single-layer NN\n",
    "\n",
    "We decided to expand on our LR implementation by adding a hidden layer and creating a simple neural network, which should be much more capable of capturing non-linearity in the image data. \n",
    "\n",
    "First, we set up the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_labels[:1800]\n",
    "y_dev = train_labels[1800:]\n",
    "train_data = DataSet(np.arange(0,1800), y_train)\n",
    "test_data = DataSet(np.arange(1800,len(train_labels)), y_dev)\n",
    "\n",
    "y_validation = train_labels[1800:]\n",
    "validation_data = DataSet(np.arange(1800,len(train_labels)), y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we prepare the tensorflow variables and graph. For this attempt, we add a single fully connected NN layer between the input and output layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height = 866\n",
    "width = 1154\n",
    "channels = 3\n",
    "n_inputs = height * width\n",
    "\n",
    "n_fc1 = 32\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "n_outputs = 2\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, height, width, channels], name=\"X\")\n",
    "    X_resized = tf.image.resize_images(X, [400, 300])\n",
    "    X_resized_flat = tf.reshape(X_resized,shape=[-1,400* 300*channels])\n",
    "\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "    \n",
    "    X_nn = tf.placeholder(tf.float32, shape=[None, 400* 300* channels], name=\"X_nn\")\n",
    "\n",
    "with tf.name_scope(\"fc1_nn\"):\n",
    "    fc1_nn = tf.layers.dense(X_resized_flat, 800, activation=tf.nn.relu, name=\"fc1_nn\")\n",
    "    #where do you use drop out layer\n",
    "    fc1_drop = tf.layers.dropout(fc1_nn, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output_nn\"):\n",
    "    logits_nn = tf.layers.dense(fc1_nn, n_outputs, name=\"output_nn\")\n",
    "    Y_proba = tf.nn.softmax(logits_nn, name=\"Y_proba\")\n",
    "    \n",
    "with tf.name_scope(\"train_nn\"):\n",
    "    xentropy_nn = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_nn, labels=y)\n",
    "    loss_nn = tf.reduce_mean(xentropy_nn)\n",
    "    optimizer_nn = tf.train.AdamOptimizer()\n",
    "    training_op_nn = optimizer_nn.minimize(loss_nn)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits_nn, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))   \n",
    "    \n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then fit the NN and monitor performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val, y_val = validation_data.next_batch(80)\n",
    "n_epochs = 10\n",
    "batch_size = 30\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 5\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 30\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(train_data.num_examples // batch_size):\n",
    "            X_batch, y_batch = train_data.next_batch(batch_size)\n",
    "            #X_batch =X_batch.reshape(height*width*channels)\n",
    "            sess.run(training_op_nn, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            if iteration % check_interval == 0:\n",
    "                loss_val = loss_nn.eval(feed_dict={X: X_val, y: y_val})\n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val,y: y_val})\n",
    "        print(\"Epoch {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
    "                  epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "    save_path = saver.save(sess, \"./my_isd_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output from our runs:\n",
    "\n",
    "Epoch 0, train accuracy: 73.3333%, valid. accuracy: 71.2500%, valid. best loss: 10.095164\n",
    "\n",
    "Epoch 1, train accuracy: 70.0000%, valid. accuracy: 76.2500%, valid. best loss: 8.895315\n",
    "\n",
    "Epoch 2, train accuracy: 80.0000%, valid. accuracy: 73.7500%, valid. best loss: 5.483994\n",
    "\n",
    "Epoch 3, train accuracy: 60.0000%, valid. accuracy: 73.7500%, valid. best loss: 4.458233\n",
    "\n",
    "Epoch 4, train accuracy: 46.6667%, valid. accuracy: 62.5000%, valid. best loss: 3.471657\n",
    "\n",
    "Epoch 5, train accuracy: 73.3333%, valid. accuracy: 60.0000%, valid. best loss: 2.967641\n",
    "\n",
    "Epoch 6, train accuracy: 96.6667%, valid. accuracy: 72.5000%, valid. best loss: 2.967641\n",
    "\n",
    "Epoch 7, train accuracy: 93.3333%, valid. accuracy: 75.0000%, valid. best loss: 2.715569\n",
    "\n",
    "Epoch 8, train accuracy: 93.3333%, valid. accuracy: 77.5000%, valid. best loss: 2.494355\n",
    "\n",
    "Epoch 9, train accuracy: 100.0000%, valid. accuracy: 73.7500%, valid. best loss: 2.358074\n",
    "\n",
    "From the results, we see a marked improvement on the training accuracy, as the single-layer NN captures more of the complexity in the data. The test accuracy is also slightly better than before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM\n",
    "\n",
    "Next, we fit a model on our data using the Linear SVM algorithm. As we wanted to generate more results by applying data augmentation to the data as it was fed to the algorithm, we had to use a modified DataSet class for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSetSVM(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                image_indices,\n",
    "                labels,\n",
    "                dataPath = data_path,\n",
    "                seed=None,\n",
    "                aug_array = []):\n",
    "        seed1, seed2 = random_seed.get_seed(seed)\n",
    "        # If op level seed is not set, use whatever graph level seed is returned\n",
    "        np.random.seed(seed1 if seed is None else seed2)\n",
    "        self._num_examples = len(image_indices)\n",
    "        self._image_indices = image_indices\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "        self.path = dataPath\n",
    "        self.aug_array = aug_array\n",
    "\n",
    "    @property\n",
    "    def image_indices(self):\n",
    "        return self._image_indices\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "\n",
    "    def next_batch(self, batch_size, shuffle=True):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        \n",
    "        # pick augmentation sequence to apply.\n",
    "        # applying an augmentation sequence means we will return twice the amount of batch_size items,\n",
    "        # as each image sample will be read, and a copy of it will be augmented, making the samples 2*batch_size\n",
    "        aug_seq = np.random.choice(self.aug_array, 1)[0] if self.aug_array else None\n",
    "        \n",
    "        start = self._index_in_epoch\n",
    "        # Shuffle for the first epoch\n",
    "        if self._epochs_completed == 0 and start == 0 and shuffle:\n",
    "            perm0 = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm0)\n",
    "            self._image_indices = self.image_indices[perm0]\n",
    "            self._labels = self.labels[perm0]\n",
    "        # Go to the next epoch\n",
    "        if start + batch_size > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            # Get the rest examples in this epoch\n",
    "            rest_num_examples = self._num_examples - start\n",
    "            images_rest_part = self._image_indices[start:self._num_examples]\n",
    "            labels_rest_part = self._image_indices[start:self._num_examples]\n",
    "            # Shuffle the data\n",
    "            if shuffle:\n",
    "                perm = np.arange(self._num_examples)\n",
    "                np.random.shuffle(perm)\n",
    "                self._image_indices = self.image_indices[perm]\n",
    "                self._labels = self.labels[perm]\n",
    "          # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size - rest_num_examples\n",
    "            end = self._index_in_epoch\n",
    "            images_new_part = self._image_indices[start:end]\n",
    "            labels_new_part = self._labels[start:end]\n",
    "            labels = np.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "            images, labels= load_images_flat(np.concatenate((images_rest_part, images_new_part), axis =0), labels, path = self.path, seq = aug_seq)\n",
    "            return images, labels\n",
    "        else:\n",
    "            self._index_in_epoch += batch_size\n",
    "            end = self._index_in_epoch\n",
    "            labels = self._labels[start:end]\n",
    "            images, labels = load_images_flat(self._image_indices[start:end], labels, path = self.path, seq = aug_seq)            \n",
    "            return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Augmentation\n",
    "\n",
    "As we load images for training, we want to make a copy of each image, apply a random set of augmentations to it and add it to our dataset. This is so that we can generate more images for training that are roughly based on the current dataset and have some reasonable differences. For SVM, we chose to add some amount of Gaussian Blur, flip the image left-right, or flip it up-down. In order to implement this, we used the imgaug library, which allows us to define sequences of augmentations to be applied to each image passed to the sequence. Then we can define a sequence for every combination of augmentations listed above, and select one randomly to apply to each image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# see https://github.com/aleju/imgaug\n",
    "flip_lr_seq = iaa.Sequential([\n",
    "    iaa.Fliplr(1), # horizontally flip\n",
    "])\n",
    "\n",
    "flip_ud_seq = iaa.Sequential([\n",
    "    iaa.Flipud(1), # vertically flip\n",
    "])\n",
    "\n",
    "gauss_1_seq = iaa.Sequential([\n",
    "    iaa.GaussianBlur(1.0), # blur images with a sigma of 0 to 3.0\n",
    "])\n",
    "\n",
    "flip_seq = iaa.Sequential([\n",
    "    iaa.Flipud(1), # vertically flip\n",
    "    iaa.Fliplr(1), # horizontally flip\n",
    "])\n",
    "\n",
    "flip_ud_gauss_seq = iaa.Sequential([\n",
    "    iaa.Flipud(1), # vertically flip\n",
    "    iaa.GaussianBlur(1.0),\n",
    "])\n",
    "\n",
    "flip_lr_gauss_seq = iaa.Sequential([\n",
    "    iaa.Fliplr(1), # vertically flip\n",
    "    iaa.GaussianBlur(1.0),\n",
    "])\n",
    "\n",
    "flip_2_gauss_seq = iaa.Sequential([\n",
    "    iaa.Flipud(1), # vertically flip\n",
    "    iaa.Fliplr(1), # horizontally flip\n",
    "    iaa.GaussianBlur(1.0),\n",
    "])\n",
    "# pass this array to DataSet object. during next_batch() one of the seq in the array will be picked randomly and applied when loading data\n",
    "seq_array = [flip_lr_seq, flip_ud_seq, gauss_1_seq, flip_seq, flip_ud_gauss_seq, flip_lr_gauss_seq, flip_2_gauss_seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see an example of how the imgaug library works, and how we use sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Sequential(name=UnnamedSequential, augmenters=[Fliplr(name=UnnamedFliplr, parameters=[Binomial(Deterministic(float 1.00000000))], deterministic=False)], deterministic=False)]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.choice(seq_array, 1))\n",
    "\n",
    "img = Image.open(data_path + \"train/\"+str(3)+\".jpg\")\n",
    "seq = iaa.Sequential([\n",
    "#     iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Flipud(1), # horizontally flip image\n",
    "    iaa.GaussianBlur(sigma=(1.0)) # blur images with a sigma of 1.0\n",
    "])\n",
    "# img.show()\n",
    "img.thumbnail([500,600])\n",
    "img.save(\"example_no_aug1.png\")\n",
    "arrg = np.array(img)\n",
    "im_aug = seq.augment_images(arrg)\n",
    "new_img = Image.fromarray(im_aug,'RGB')\n",
    "img.thumbnail([500,600])\n",
    "new_img.save(\"example_aug1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of an image without aug:\n",
    "![example_no_aug1](example_no_aug1.png)\n",
    "\n",
    "Example of an image with aug:\n",
    "![example_aug1](example_aug1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now prepare the data for loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare labels\n",
    "train_labels = pd.read_csv(data_path + \"train_labels.csv\")['invasive'].values\n",
    "y_train = train_labels[:1800]\n",
    "y_validation = train_labels[1800:]\n",
    "\n",
    "# prepare data\n",
    "train_data = DataSetSVM(np.arange(0,1800), y_train, dataPath = data_path + \"train/\", aug_array = seq_array)\n",
    "validation_data = DataSetSVM(np.arange(1800,len(train_labels)), y_validation, dataPath = data_path + \"train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also set up the parameters we will need for implementing SVM in tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svmC = 100\n",
    "num_features = 2998092\n",
    "n_epochs = 20\n",
    "batch_size = 80\n",
    "best_loss_val = np.infty\n",
    "check_interval = 5\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 8\n",
    "best_model_params = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we implement the Linear SVM in TensorFlow. We define our weights and bias, as well as the y function (y=W*x-b) we will use in the cost function. We then define the regularization and hinge loss functions in order to create the final loss function that we minimize using gradient descent. The regularization loss function penalizes us having to move misclassified examples across the margin, while the hinge function is used to determine the best margin possible. In the end we also add evaluation functions for accuracy calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set graph\n",
    "reset_graph()\n",
    "\n",
    "# inputs\n",
    "X = tf.placeholder(tf.float32, shape=[None, num_features], name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=[None], name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "# set weights and create function\n",
    "W = tf.Variable(tf.zeros([num_features,1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y_raw = tf.matmul(X,W) - b\n",
    "\n",
    "# Optimization.\n",
    "regularization_loss = tf.reduce_sum(tf.square(W))\n",
    "\n",
    "# *2 needed as the training involves augmentation, which adds each image again in an augmented form, so we get twice as big an array from load_image_flat\n",
    "hinge_loss = tf.reduce_mean(tf.maximum(tf.zeros([batch_size*2,1]), 1 - y*y_raw))\n",
    "\n",
    "svm_loss = svmC*regularization_loss + hinge_loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(svm_loss)\n",
    "\n",
    "# SVM Loss for validation set;\n",
    "# This is needed because the training involves augmentation, which adds each image again in an augmented form\n",
    "# This doesn't happen for validation\n",
    "hinge_loss_test = tf.reduce_mean(tf.maximum(tf.zeros([batch_size,1]), 1 - y*y_raw))\n",
    "svm_loss_test = svmC*regularization_loss + hinge_loss_test\n",
    "\n",
    "# Evaluation.\n",
    "predicted_class = tf.sign(y_raw);\n",
    "correct_prediction = tf.equal(y,predicted_class)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run our SVM algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val, y_val = validation_data.next_batch(80)\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        # start an epoch\n",
    "        for iteration in range(train_data.num_examples // batch_size):\n",
    "            # get a batch to run\n",
    "            X_batch, y_batch = train_data.next_batch(batch_size)\n",
    "            # run the train\n",
    "            print(X_batch.shape)\n",
    "            print(X_val.shape)\n",
    "            sess.run(train_step, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            loss_val = svm_loss_test.eval(feed_dict={X: X_val,y: y_val})\n",
    "            if loss_val < best_loss_val:\n",
    "                best_loss_val = loss_val\n",
    "                checks_since_last_progress = 0\n",
    "            else:\n",
    "                checks_since_last_progress += 1\n",
    "        # check accuracy\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        print(\"Epoch {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            print()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output:\n",
    "\n",
    "Epoch 0, train accuracy: 66.2500%, valid. accuracy: 65.0000%, valid. best loss: 0.366802\n",
    "\n",
    "Epoch 1, train accuracy: 61.2500%, valid. accuracy: 65.0000%, valid. best loss: 0.366787\n",
    "\n",
    "Epoch 2, train accuracy: 56.2500%, valid. accuracy: 65.0000%, valid. best loss: 0.366772\n",
    "\n",
    "Epoch 3, train accuracy: 53.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366757\n",
    "\n",
    "Epoch 4, train accuracy: 55.0000%, valid. accuracy: 65.0000%, valid. best loss: 0.366743\n",
    "\n",
    "Epoch 5, train accuracy: 68.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366728\n",
    "\n",
    "Epoch 6, train accuracy: 68.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366713\n",
    "\n",
    "Epoch 7, train accuracy: 67.5000%, valid. accuracy: 65.0000%, valid. best loss: 0.366699\n",
    "\n",
    "Epoch 8, train accuracy: 73.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366684\n",
    "\n",
    "Epoch 9, train accuracy: 66.2500%, valid. accuracy: 65.0000%, valid. best loss: 0.366669\n",
    "\n",
    "Epoch 10, train accuracy: 63.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366654\n",
    "\n",
    "Epoch 11, train accuracy: 62.5000%, valid. accuracy: 65.0000%, valid. best loss: 0.366640\n",
    "\n",
    "Epoch 12, train accuracy: 65.0000%, valid. accuracy: 65.0000%, valid. best loss: 0.366625\n",
    "\n",
    "Epoch 13, train accuracy: 57.5000%, valid. accuracy: 65.0000%, valid. best loss: 0.366611\n",
    "\n",
    "Epoch 14, train accuracy: 68.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366596\n",
    "\n",
    "Epoch 15, train accuracy: 65.0000%, valid. accuracy: 65.0000%, valid. best loss: 0.366581\n",
    "\n",
    "Epoch 16, train accuracy: 73.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366567\n",
    "\n",
    "Epoch 17, train accuracy: 66.2500%, valid. accuracy: 65.0000%, valid. best loss: 0.366552\n",
    "\n",
    "Epoch 18, train accuracy: 53.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366538\n",
    "\n",
    "Epoch 19, train accuracy: 57.5000%, valid. accuracy: 65.0000%, valid. best loss: 0.366523\n",
    "\n",
    "Epoch 20, train accuracy: 60.0000%, valid. accuracy: 65.0000%, valid. best loss: 0.366509\n",
    "\n",
    "Epoch 21, train accuracy: 58.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366494\n",
    "\n",
    "Epoch 22, train accuracy: 60.0000%, valid. accuracy: 65.0000%, valid. best loss: 0.366479\n",
    "\n",
    "Epoch 23, train accuracy: 62.5000%, valid. accuracy: 65.0000%, valid. best loss: 0.366465\n",
    "\n",
    "Epoch 24, train accuracy: 65.0000%, valid. accuracy: 65.0000%, valid. best loss: 0.366450\n",
    "\n",
    "Epoch 25, train accuracy: 62.5000%, valid. accuracy: 65.0000%, valid. best loss: 0.366436\n",
    "\n",
    "Epoch 26, train accuracy: 63.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366422\n",
    "\n",
    "Epoch 27, train accuracy: 61.2500%, valid. accuracy: 65.0000%, valid. best loss: 0.366407\n",
    "\n",
    "Epoch 28, train accuracy: 75.0000%, valid. accuracy: 65.0000%, valid. best loss: 0.366393\n",
    "\n",
    "Epoch 29, train accuracy: 53.7500%, valid. accuracy: 65.0000%, valid. best loss: 0.366378"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results, SVM has a very low, albeit consistent train and test accuracy. Even with additional data augmentation samples, it is unable to do better than 75% train and 65% test accuracy. This shows that SVM underfits the training data, even if we use very low regularization values (high C). As a whole, it looks like SVM cannot capture the complexities of the sample data well enough to fit it accurately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Approach: CNN\n",
    "\n",
    "Following the bad performance of our initial approaches, we decided to use Convolutional Neural Networks as the main engine for prediction. CNNs are neural networks that are specifically designed to work with image data. The convolutional layers use a specifically designed filter to reduce the dimensions of the images while maintaining the overall composition and variance of the data. A combination of convolutional, max pool, and fully connected layers allow us to build a neural network with a much better performance than our baseline models.\n",
    "\n",
    "The structure of the network is as follows:\n",
    "- Convolution layer 1\n",
    "- Convolution layer 2\n",
    "- Max pool layer\n",
    "- Fully connected layer\n",
    "- Output layer \n",
    "\n",
    "After our initial testing showed that we overfit the training data, we applied following techniques to improve model performance and avoid overfitting:\n",
    "1. Applied 25% drop out at max pool layer and fully connected layer\n",
    "2. We use data augmentation techniques such as Gaussian blur and image rotation to generate additional images variance \n",
    "\n",
    "We use tensorflow version 1.0 and trained the model using P2 GPU instance in AWS. This is because CNNs require a lot of processing power. Therefore, our opportunity to multiple tests and runs was limited by the high cost of running this on an expensive AWS server. \n",
    "\n",
    "It is also important to note that we had to resize the input images to (300,400,3) because otherwise we would run out of memory. \n",
    "\n",
    "Below we build the tensorflow graph for the models. We are testing several variants of the models to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height = 866\n",
    "width = 1154\n",
    "channels = 3\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 64\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 32\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "conv2_dropout_rate = 0.25\n",
    "\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 32\n",
    "fc1_dropout_rate = 0.25\n",
    "\n",
    "n_outputs = 2\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, height, width, channels], name=\"X\")\n",
    "    X_resized = tf.image.resize_images(X, [300, 360])\n",
    "\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_resized, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 150 * 180])\n",
    "    pool3_flat_drop = tf.layers.dropout(pool3_flat, conv2_dropout_rate, training=training)\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat_drop, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1_drop, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Possibly remove this\n",
    "def get_model_params():\n",
    "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "def restore_model_params(model_params):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try to fit the data without using data augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train accuracy: 60.0000%, test accuracy: 58.1818%, loss: 0.665791, best loss: 0.665741\n",
      "Epoch 1, train accuracy: 74.2857%, test accuracy: 72.7273%, loss: 0.599543, best loss: 0.601388\n",
      "Epoch 2, train accuracy: 68.5714%, test accuracy: 67.2727%, loss: 0.606988, best loss: 0.578064\n",
      "Epoch 3, train accuracy: 81.4286%, test accuracy: 76.3636%, loss: 0.566922, best loss: 0.524850\n",
      "Epoch 4, train accuracy: 88.5714%, test accuracy: 85.4545%, loss: 0.434947, best loss: 0.434941\n",
      "Epoch 5, train accuracy: 98.5714%, test accuracy: 80.0000%, loss: 0.439690, best loss: 0.413104\n",
      "Epoch 6, train accuracy: 97.1429%, test accuracy: 72.7273%, loss: 0.781371, best loss: 0.413104\n",
      "Epoch 7, train accuracy: 98.5714%, test accuracy: 74.5455%, loss: 0.544343, best loss: 0.413104\n",
      "Epoch 8, train accuracy: 100.0000%, test accuracy: 72.7273%, loss: 0.884409, best loss: 0.413104\n",
      "Epoch 9, train accuracy: 100.0000%, test accuracy: 72.7273%, loss: 0.588346, best loss: 0.413104\n",
      "Epoch 10, train accuracy: 100.0000%, test accuracy: 74.5455%, loss: 0.630064, best loss: 0.413104\n",
      "Epoch 11, train accuracy: 100.0000%, test accuracy: 78.1818%, loss: 0.734039, best loss: 0.413104\n",
      "Epoch 12, train accuracy: 97.1429%, test accuracy: 80.0000%, loss: 0.463004, best loss: 0.413104\n",
      "Epoch 13, train accuracy: 98.5714%, test accuracy: 69.0909%, loss: 0.877005, best loss: 0.413104\n",
      "Epoch 14, train accuracy: 100.0000%, test accuracy: 70.9091%, loss: 0.870427, best loss: 0.413104\n",
      "Epoch 15, train accuracy: 100.0000%, test accuracy: 70.9091%, loss: 0.999083, best loss: 0.413104\n",
      "Epoch 16, train accuracy: 100.0000%, test accuracy: 69.0909%, loss: 0.917802, best loss: 0.413104\n",
      "Epoch 17, train accuracy: 100.0000%, test accuracy: 70.9091%, loss: 0.906862, best loss: 0.413104\n",
      "Epoch 18, train accuracy: 100.0000%, test accuracy: 70.9091%, loss: 0.953206, best loss: 0.413104\n",
      "Epoch 19, train accuracy: 100.0000%, test accuracy: 70.9091%, loss: 1.042577, best loss: 0.413104\n",
      "Epoch 20, train accuracy: 100.0000%, test accuracy: 69.0909%, loss: 1.020047, best loss: 0.413104\n",
      "Epoch 21, train accuracy: 100.0000%, test accuracy: 69.0909%, loss: 1.470435, best loss: 0.413104\n",
      "Epoch 22, train accuracy: 100.0000%, test accuracy: 70.9091%, loss: 1.002305, best loss: 0.413104\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "y_test = train_labels[2240:]\n",
    "test_data = DataSet(np.arange(2240,len(train_labels)), y_test)\n",
    "train_data =  DataSet(np.arange(0,2240), train_labels[:2240])\n",
    "X_val, y_val = test_data.next_batch(55)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 70\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 5\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 120\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(train_data.num_examples // batch_size):\n",
    "            X_batch, y_batch = train_data.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            if iteration % check_interval == 0:\n",
    "                loss_val = loss.eval(feed_dict={X: X_val,\n",
    "                                                y: y_val})\n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        loss_val = loss.eval(feed_dict={X: X_val,\n",
    "                                                y: y_val})\n",
    "        print(\"Epoch {}, train accuracy: {:.4f}%, test accuracy: {:.4f}%, loss: {:.6f}, best loss: {:.6f}\".format(\n",
    "                  epoch, acc_train * 100, acc_test * 100, loss_val, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_isd_model22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXd4XNW19//Z04vKqNlyldxtGSM3cFzAGAKBhE4u2DEh\nQBLSSH5JKCEhN29u8iYhIdyEvKkQ+iU2hISSSwvVxgbjgmyD5W4sW7Ylq47K9Dn798eZOVYZSSNp\nVDzan+fxY82Zfc5ZMzr6nnXWXmttIaVEoVAoFOmFaagNUCgUCkXqUeKuUCgUaYgSd4VCoUhDlLgr\nFApFGqLEXaFQKNIQJe4KhUKRhihxVygUijREibtCoVCkIUrcFQqFIg2xDNWJ8/PzZXFx8VCdXqFQ\nKE5Ltm3bViulLOhp3JCJe3FxMVu3bh2q0ysUCsVpiRCiIplxKiyjUCgUaYgSd4VCoUhDlLgrFApF\nGqLEXaFQKNIQJe4KhUKRhvQo7kKIh4UQJ4UQH3XxvhBC/E4IcUAIsVMIMT/1ZioUCoWiNyTjuT8K\nXNzN+5cA02L/bgH+1H+zFAqFQtEfesxzl1KuF0IUdzPkCuBxqa/Xt0kI4RFCjJFSnkiRjYPO1r3H\n2XukrsdxMybmsXDG2Hbbahp9vL7tEJrWt+ULzWYTn140lSy3vd32ddsrqKxpMl4vmzOBokJPuzEf\nfXySHQeqEx530pgclpwxvsvzNvmCvLTpANGo1ie72yKEYPncIsblZ7bb/uGhk+w8mNi+ZMjJdHDJ\noqkIIYxtwXCEf727n2Ao0u2+JpPgwoWTyc92tdu+qbySg8ca+mzT2PxMVswrbret2RfkxRR9l4qu\nsVrNXL5kOg7bKRmTUvLqlkPUeX2Afi2eP7+YwtyMLo/T3+uyL5w9ayzTxucN6DlSUcQ0Djja5nVl\nbFsncRdC3ILu3TNx4sQUnHpg+ONz26j1+mijIZ2QEvKzXTz8vfbi/uqWgzz9Vnm3+3aHlBCJaFx/\n0RxjW02jj/ue3gSAEPqY3RW1/N8vrTDGaJrkN39/n5rGznZLCRazicenXEGG05bwvC9s3Ncvuzue\nr77Zz61XndVu+19fLOPjE419Okd8qd9JY3KYVZRvbH97ewWPv7oToMffV32Tn2+0sak1EOLete8R\njmj9sqmkuIDROW5j+7/e3c/aN3el5LtUdI2U4LJZuHTJdGPbweMN/PE5vTgy/rdyvLaZ21cuTniM\nqKZx39ObqG/yD+rvKzfLeVqIe9JIKR8AHgBYuHDhsFyZW0pJY0uAa5bP4gufOrPLcY+9soPnN+5D\nStnOk2xsDpCb6eDR71/Rp/P/n0fWsW5HBasvPMM47js7jwDwl9s+w5i8DP72+kc89dYu6pr85GU5\nAdhzpJaaRh/fvXYR580tbnfM/ZX13PbH13h3VyUXLZyc8DOv31HB3Kmj+cnN5/XJ7rbc/sfXqGn0\nddp+sqGVz3xiKl+5fEGvj+kLhrnhZ8+zbkdFO3Ffv/0I4/Iz+eN3Lmn3e+jIfU9vYuNHldxy2Xys\nFjMAm3YdIxzRuPdrn2TGhN7/oVXVt3DLr1/knZ1H+OzyWYD+Xa7bUUHplNH89Ivn9fqYiuT51u9e\nYd2OI+3Efd2OCixmE499/3IyXXb++NxW3io7jD8Yxmm3djpG+eFa6pv83LFyMeecOXwdzr6QimyZ\nY8CENq/Hx7adlrQGwkSiGp4OYZGOZGc4iEQ1WgPhdtsbWwJkZzj6fP5zSydS3dDK3qOnwkLrdlQw\nfUIuY/IyjDFSwoaY6MfH2KxmFs0a1+mYU8flMDYvg/XbE1ct76usp6q+leWlRX22uy35Hhc1ja3t\ntvkCYVoDYQo87i726h6X3crZs8ay8cOjRGLhjlqvj48On2R5aVG3wg6wvHQiLf4QZfurjG3rdlRQ\nmOtm+vjcPtlUmJvBzIl5rNtx6ns9cKyeE3UtnFuaXkIxHFleWsTeo3VU1bcAuhf+zs6jzJ9eSKbL\nbowJhqNs3n084THW7ajAYbNw9syxCd8/nUmFuL8A3BDLmvkE4D2d4+2NLQEAPD0ItCdDv3i8rcH2\n+7cGety3OxaXjMdqMbF+hy7cR6q9fHyisZ3wji/IYuq4HENUIlGNDR8eZdGscQm9EyEE55YW8eHH\nJ6lr8nd6f/32CqwWE5+Y3fnG0BcKPC5qGn1IeerhrDYWAy3wuLrarUfOLS3C2xpkRyw++s7OI0hJ\nUkI6d2ohmS4b62Lfa0Ozn50HT3JuEjeG7lheWkRFlZfDVY0ArNtxBIvZxOLZXc9vKFJD3NOO/63s\n+riG+iZ/u7+VWUX55Ge72t2A44QjUd79qJJPlIzDbhuyNlsDRjKpkGuA94AZQohKIcQXhRBfFUJ8\nNTbkJeAQcAB4EPj6gFk7CMTFPTujB8/drQt4Y3Ogw/5Bsnvw+rvD5bBy1syxvLPzCNGoxvqdRzAJ\nwbI5E9qNO7e0iAPHGjhW28z2A1U0+0Is70bkEnn7ANGoxjsfHuWsGWNxOxLH43tLQbabYDhKsz9k\nbIuHafoj7gumF+J2WFkf+0Ndv+MI08bnMrbDxG0iLGYTy+ZM4P3dx/AHw2z48CialP1+Wlk6ZwIm\nk2D9jiMxz/EIC2eM6XJuQ5E6RuW4KSnKZ932Cj20uPNIJy/cZBKcWzqRsv1VNHVwxD7YX0WLP5Sy\nJ9bhRo/iLqVcJaUcI6W0SinHSykfklL+WUr559j7Ukr5DSnlFCnlHCnlad3q0duiXwA9e+76+97W\n9uLubemf5w66Nxj3UNfvqODMKaPIyXS2G3POnAkIAet3VLBuxxEynDbmTSvs8pgdvf04Ow+dpLEl\nwLkpvMDjAt427h4P0xRk913crRYzS8+YwKZdxzh4vIGDxxt6Ff5YXlpEKBzl/d3HWLejgkljPEwY\nldVne0C/DuZOHc36HRV8eOgkDc2BtBWL4ci5pUUcrWlif2V9l1748tKJRDXJxo+Ottu+fnsFWS47\npVNHD6bJg4aqUO2A4bm7kwvLxMcD+INhguFoj15/TyyYPga3w8qjr+zoMhael+3ijEmjeKvsMO+X\nH2PpGeONicKuaOvtx1m/owKX3crCGWP6ZXNbEoq714fZJPBk9u/Gd27pRPyhCPc/8z5CwDlzkhf3\nmRPzKfC4+Mf6Pew7Wp8yEV5eWsTJRh8Pv7Qdp93Cwpmp+y4V3bNszgTMJsHvn93SpRdeXKjfxOMh\nOdAn6N/fc5xlcyZgMaenDKbnp+oHjS0BhIAsd/eP1VkuO0LoYZg48fh7fz13m9XM4tnjOVzl7TYW\nvrx0IlX1rQRCkaSEqq23D3qO+Lu7Kll8xnhs1u5vDL0h7p3XtplUrWn0kZftwmzq3yU3e1IBuVlO\nDld5OXPyaHKznD3vFMNkEpx75kQqqrwAKcuOWFQyDpvFzOEqL4tnj8duTb/47XAly21n3rRCDld5\nu/TChRAsLy2i/HCN8QT5fvkxQuEo585N34lvJe4d8LYGyXLZexQhs9lEptPeznM3JmN78PqTIS7W\n3cXCl5yhex15WU5KintcmMXw9l/YuI+7/vIGd/75DfzBSLex+r6Q5bZjs5ip8bYNy/j6FZKJYzaZ\nOOdMff6hLxkp8fDT7OKCfsX/2xLP5AFUSGYIiF8H3Xnh8TE/engdd/3lDR59ZQejPC5mTshPOD4d\nUC5GBxpbAklPiGZn2Ntly8S9+P6GZQDOmFzAxWdP4cIEeelxMpw2Pn/RHHIyHZhMyWV8XLuihGfe\n3o2UkkynjRXzipkzeVS/7W2LEMLImIlT4/VRUpSaP6RLF0+nqTXE0g6TzMlQXJjNlctmsCCFYSiA\na5bPwu2wcmaKv0tFzywuGc/586u5fOn0LscU5mZw9bkzOVBZD8CEgiw+uXBS0n83pyNK3DvQ2IsJ\nUU+GI7Hn3s+wDOge6tevXNjjuKvOmdmr45ZOGU3plIGfQMpvI+5RTaPO60uZpzw6x813/mNRn/YV\nQnDzp+emxI62TBmb0676VTF42G0Wvv3Znq+HGy8uHQRrhg8qLNOBxpZg0kVIHnf7sIzXmIztv+d+\nulOQ7TLCMo3NAaKaTElYRqFQJIcS9w54WwNGJkxPeDIcRuok6J6722HtMWtlJFDgcdHQ7CcciRoi\n39fqVIVC0XuUuLchGI7gD0aS9tyzMxz4gmFC4SigT8amIiSTDhR4XEgJdU1+alNQwKRQKHqHEvc2\nJFvAFOdUC4KAsX9/+sqkEwXZupde2+gzPPeO7XYVCsXAocS9DadSGZPNlnG026+xJZD0vumOUcjk\n9VHT6MPtsOJydO57o1AoBgYl7m3obRGSxxB3fb/+Ng1LJ/Ky9eKimkZd3FVIRqEYXJS4t6HBaBqW\nZMzdfaoFQSSq0ewLpSTHPR2wWy1ku+3UNLZS421Vk6kKxSCjxL0N3l6GZU41DwsaHeeU536KAo/L\nCMvkZyffJkChUPQfJe5taGwJ4LRZku7t7LBZcNgsNLYEkm44NpLIz3ZRebKJZl9Iee4KxSCjxL0N\nfcl28WTY8bYETsXrM1VYJk6Bx8XJeBqkypRRKAYVJe5t0FsP9E6cs90OGluCKW0ali609dbVhKpC\nMbgocW9DX4qQPBkOGlsDKe0rky609daVuCsUg4sS9zb0piNknOwMO43NARpbglgtJpx21YstTlzQ\nTUKQm6kmVBWKwUSJe4yoptHk65vn3uwL0dDsx5Ph6Ndiy+lGXNxzs5yY03S1G4ViuKL+4mI0tYaQ\nMvkc9zgetx1NSiprmlQ3yA5kux1YzCYVklEohgAl7jHi/WH64rkDHKluUvH2DphMggmjspjYz0Wo\nFQpF71EB4hi97SsTJ+7phyJR1TQsAT+9+TysFuVDKBSDjRL3GL3tCBmn7XjluXcmS4WqFIohQblU\nMYwK097mubcZrzpCKhSK4YIS9xiNrUHMJoHbYevVfhkOm7HIrmoaplAohgtK3GM0tgTIznD0ejV0\nk0kYHrsKyygUiuGCEvcY3j4UMMWJT6SqpmEKhWK4oMQ9ht5Xpm/iHN9Pee4KhWK4MKKzZV7fdogT\ndS0AnKhrYUIf87Gz3XaEgCxX7+L1CoVCMVCMWHFv8gX53T+2YBICIUAIwcyJ+X061hmTCvC2BlWJ\nvUKhGDaMWHGvqPIC8J9fOIcF08f061gXnTWFi86akgqzFAqFIiWMWFezoqoRgOLR2UNsiUKhUKSe\nESvuh6u9ZDpt5GapVrQKhSL9GLHiXlHlpagwW7XoVSgUaUlS4i6EuFgIsVcIcUAIcVeC94uEEG8I\nIXYKId4WQoxPvampQ9MkR6q9FKmQjEKhSFN6FHchhBn4A3AJUAKsEkKUdBj2a+BxKeWZwE+AX6Ta\n0FRysrEVfyhCUaFnqE1RKBSKASEZz/1s4ICU8pCUMgSsBa7oMKYEeDP281sJ3h9WVFTrmTLFhcpz\nVygU6Uky4j4OONrmdWVsW1t2AFfHfr4KyBRC5PXfvIEhngY5UYVlFApFmpKqCdXbgeVCiDJgOXAM\niHYcJIS4RQixVQixtaamJkWn7j0VVY2MynHjsluHzAaFQqEYSJIR92PAhDavx8e2GUgpj0spr5ZS\nzgPujm1r7HggKeUDUsqFUsqFBQUF/TC7fxyu9qr8doVCkdYkI+5bgGlCiElCCBuwEnih7QAhRL4Q\nIn6s7wMPp9bM1BGORDlW20yRircrFIo0pkdxl1JGgFuBV4HdwNNSyl1CiJ8IIS6PDTsP2CuE2AeM\nBn42QPb2m8qaJjRNUjRaZcooFIr0JaneMlLKl4CXOmz7UZufnwGeSa1pA8PhKpUpo1Ao0p8RV6Fa\nUe3FYjYxNj9zqE1RKBSKAWPkiXuVl/EFmVhUe16FQpHGjDiFq6huVJWpCoUi7RlR4u4LhKn1+lVP\nGYVCkfaMKHFv8gUByMlUa50qFIr0ZkSJe2sgDIDboSpTFQpFejOixN0XE3fVdkChUKQ7I0rcleeu\nUChGCiNK3H2BEAAuh22ILVEoFIqBZYSJu/LcFQrFyGBEiXs8LONS4q5QKNKcESXuvmAYm9WsqlMV\nCkXaM6JUrjUQViEZhUIxIhhR4u4LhFUapEKhGBGMKHFXnrtCoRgpjChx9wXCajJVoVCMCJS4KxQK\nRRoyosS9NajCMgqFYmQwosRdee4KhWKkMGLEPRrVCIQiuO2q9YBCoUh/Roy4+4KqOlWhUIwcRoy4\nq46QCoViJDFixN2n+sooFIoRhBJ3hUKhSENGjLi3BlVYRqFQjBxGjLgrz12hUIwkRoy4GxOqqnGY\nQqEYAYwYcVeeu0KhGEmMGHFvDYSwWcxYLeahNkWhUCgGnBEk7qr1gEKhGDmMGHH3qV7uCoViBDFi\nxF157gqFYiQxYsRddYRUKBQjiREl7ioNUqFQjBQsQ23AYNEaVJ67YmQSDoeprKwkEAgMtSmKXuBw\nOBg/fjxWa990KylxF0JcDNwPmIG/Sinv6fD+ROAxwBMbc5eU8qU+WTRAqAlVxUilsrKSzMxMiouL\nEUIMtTmKJJBSUldXR2VlJZMmTerTMXoMywghzMAfgEuAEmCVEKKkw7AfAk9LKecBK4E/9smaASK+\nUIfy3BUjkUAgQF5enhL20wghBHl5ef162kom5n42cEBKeUhKGQLWAld0GCOBrNjP2cDxPls0AKiF\nOhQjHSXspx/9/Z0lI+7jgKNtXlfGtrXlx8D1QohK4CXgm/2yKsWohToUiqGjrq6OuXPnMnfuXAoL\nCxk3bpzxOhQKJXWMm266ib179/b63JdeeinLli3r9X7pQKomVFcBj0op7xNCLAaeEEKcIaXU2g4S\nQtwC3AIwceLEFJ26Z4y+Mmr9VIVi0MnLy2P79u0A/PjHPyYjI4Pbb7+93RgpJVJKTKbE/uYjjzzS\n6/PW19ezc+dOHA4HR44cGTDNiUQiWCzDLzclGc/9GDChzevxsW1t+SLwNICU8j3AAeR3PJCU8gEp\n5UIp5cKCgoK+WdwHfMpzVyiGHQcOHKCkpITVq1cze/ZsTpw4wS233MLChQuZPXs2P/nJT4yxy5Yt\nY/v27UQiETweD3fddRelpaUsXryYkydPJjz+M888w5VXXsl1113H2rVrje1VVVVcccUVnHnmmZSW\nlvL+++8D+g0kvu2mm24C4Prrr+e5554z9s3IyADg9ddf57zzzuPSSy9lzpw5AFx22WUsWLCA2bNn\n89e//tXY58UXX2T+/PmUlpZy0UUXoWkaU6dOpb6+HoBoNMrkyZON16kimdvNFmCaEGISuqivBD7X\nYcwR4ALgUSHELHRxr0mlof2hVcXcFQoAHvzfD/j4RGNKjzlpjIcvXzq/T/vu2bOHxx9/nIULFwJw\nzz33kJubSyQSYcWKFXz2s5+lpKR9/obX62X58uXcc889fPe73+Xhhx/mrrvu6nTsNWvW8POf/5zs\n7GxWr17NnXfeCcA3vvENLrzwQm699VYikQg+n48dO3bwy1/+knfffZfc3NykhHbr1q2Ul5cbTwSP\nPfYYubm5+Hw+Fi5cyDXXXEMwGORrX/sa77zzDkVFRdTX12MymVi1ahV/+9vfuPXWW3n11Vc566yz\nyM3N7dN32BU9eu5SyghwK/AqsBs9K2aXEOInQojLY8NuA74shNgBrAFulFLKlFraD5TnrlAMT6ZM\nmWIIO+iCPH/+fObPn8/u3bspLy/vtI/T6eSSSy4BYMGCBRw+fLjTmOPHj3PkyBEWL15MSUkJmqax\nZ88eAN5++22+8pWvAGCxWMjKyuLNN9/kuuuuMwQ2GaFdvHhxu1DPb37zG+NporKykoMHD/Lee++x\nYsUKioqK2h33i1/8Io899hgADz/8sPGkkEqSChTFctZf6rDtR21+LgeWpta01NGqerkrFAB99rAH\nCrfbbfy8f/9+7r//fjZv3ozH4+H6669PmApos52aOzObzUQikU5jnnrqKWpraykuLgZ0b3/NmjX8\n13/9F5B8JorFYkHT9KnDaDTa7lxtbX/99ddZv349mzZtwul0smzZsm7TGIuLi8nJyeGtt96irKyM\niy66KCl7esOIaD+gPHeFYvjT1NREZmYmWVlZnDhxgldffbXPx1qzZg2vv/46hw8f5vDhw2zevJk1\na9YAsGLFCv785z8DumA3NTVx/vnn89RTTxnhmPj/xcXFbNu2DYBnn32WaDSa8Hxer5fc3FycTie7\ndu1iy5YtACxZsoS33nqLioqKdscF3XtfvXo1K1eu7HIiuT+MCHFvDYSxWkxqoQ6FYhgzf/58SkpK\nmDlzJjfccANLl/YtGHDw4EFOnDjRLtwzbdo0HA4H27Zt4/e//z2vvvoqc+bMYeHChezZs4fS0lLu\nvPNOzj33XObOncsdd9wBwFe+8hVee+01SktLKSsrw263JzznZz7zGXw+HyUlJfzwhz9k0aJFAIwe\nPZo//elPXHHFFZSWlrJ69Wpjn6uuugqv18uNN97Yp8/ZE2KoQuMLFy6UW7duHZRz/eHZLWwqP8YT\nd185KOdTKIYTu3fvZtasWUNthqIDmzZt4vvf/z5vvfVWl2MS/e6EENuklAu72MVg+CVnDgCqr4xC\noRhO/OxnP+OBBx5ol6KZakZGWEZ1hFQoFMOIu+++m4qKChYvXjxg5xgR4q577qo6VaFQjBxGhLir\nJfYUCsVIY0SIu1piT6FQjDRGjLirCVWFQjGSSHtxj2oa/lAEl1o/VaEYElasWNGpIOm3v/0tX/va\n17rdL96kKxHPPfccQgijpYCiM2kv7v6gXi6sPHeFYmhYtWpVp5S/tWvXsmrVqj4fc82aNSxbtsyo\nOh0ouqpIPR1Ie3FXfWUUiqHls5/9LC+++KKxMMfhw4c5fvw455xzDi0tLVxwwQXMnz+fOXPm8Pzz\nz/d4vJaWFjZs2MBDDz3U6abxy1/+kjlz5lBaWmp0ijxw4ACf/OQnKS0tZf78+Rw8eJC3336bSy+9\n1Njv1ltv5dFHHwX0lgPf+973mD9/Pn//+9958MEHOeussygtLeWaa67B5/MBUF1dzVVXXUVpaSml\npaW8++67/OhHP+K3v/2tcdy7776b+++/v1/fX19J+yKm+iY/AJ4MxxBbolAMPQ2PPU7ocEVKj2kr\nLiLnCzd0+X5ubi5nn302L7/8MldccQVr167l2muvRQiBw+Hg2WefJSsri9raWj7xiU9w+eWXd9vY\n6/nnn+fiiy9m+vTp5OXlsW3bNhYsWMDLL7/M888/z/vvv4/L5TL6uKxevZq77rqLq666ikAggKZp\nHD16tMvjg77AyAcffADoK0l9+ctfBuCHP/whDz30EN/85jf51re+xfLly42eMy0tLYwdO5arr76a\nb3/722iaxtq1a9m8eXNvv9KUkPaee0WV3ru6aHT2EFuiUIxc2oZm2oZkpJT84Ac/4Mwzz+STn/wk\nx44do7q6uttjrVmzhpUrVwKwcuVKIzTz+uuvc9NNN+FyuQD9ptLc3MyxY8e46qqrAHA4HMb73XHd\nddcZP3/00Uecc845zJkzhyeffJJdu3YB8OabbxrzBmazmezsbIqLi8nLy6OsrIx///vfzJs3j7y8\nvKS/p1SS9p774WovLruVAk/Pv1CFIt3pzsMeSK644gq+853v8MEHH+Dz+ViwYAEATz75JDU1NWzb\ntg2r1UpxcXG3rXLr6+t58803+fDDDxFCEI1GEUJw77339sqetq18gU7nbNvO98Ybb+S5556jtLSU\nRx99lLfffrvbY3/pS1/i0UcfpaqqiptvvrlXdqWSEeC5e5k4Okut/q5QDCEZGRmsWLGCm2++ud1E\nqtfrZdSoUVit1natcbvimWee4fOf/zwVFRUcPnyYo0ePMmnSJN555x0uvPBCHnnkESMmXl9fT2Zm\nJuPHjzeWygsGg/h8PoqKiigvLycYDNLY2Mgbb7zR5Tmbm5sZM2YM4XCYJ5980th+wQUX8Kc//QnQ\nJ169Xi+gd3t85ZVX2LJlC5/61Kf69oWlgLQWdyklFdVeigs9Q22KQjHiWbVqFTt27Ggn7qtXr2br\n1q3MmTOHxx9/nJkzZ3Z7jDVr1hghljjXXHMNa9as4eKLL+byyy9n4cKFzJ07l1//+tcAPPHEE/zu\nd7/jzDPPZMmSJVRVVTFhwgSuvfZazjjjDK699lrmzZvX5Tl/+tOfsmjRIpYuXdrOvvvvv5+33nqL\nOXPmsGDBAmPVKJvNxooVK7j22msxm4euzXhat/yt8/q46Zf/4iuXzeczi6cN6LkUiuGKavk7uGia\nZmTaTJvWP93pT8vftPbcD1frj0lFhWoyVaFQDDzl5eVMnTqVCy64oN/C3l/SekK1oiom7ipTRqFQ\nDAIlJSUcOnRoqM0A0txzr6huJDfLSaYr8dJYCoVCka6ktbgfrvIqr12hQE8uUJxe9Pd3lrbiHo1q\nVNY0Uazi7YoRjsPhoK6uTgn8aYSUkrq6OhyOvlfWp23M/XhdC+GIpjx3xYhn/PjxVFZWUlNTM9Sm\nKHqBw+Fg/Pjxfd4/bcXdaDugctwVIxyr1cqkSZOG2gzFIJO2YZnD1V5MJsGEgqyhNkWhUCgGnbQV\n94oqL2PzMrBZh65CTKFQKIaK9BX36kaKRquQjEKhGJmklbgHwxF8gTANzX6q6ltVZapCoRixpM2E\n6v7KOu748xto2ql0r0ljlOeuUChGJmkj7sfrWtA0yTXLZ5HttmO3mpk/rXCozVIoFIohIW3EPRDS\nF8L+9KKpamEOhUIx4kmbmHtc3B02lR2jUCgUaSPuwVAUAIctbR5GFAqFos+kjbgHQhHMJoHFnDYf\nSaFQKPpMUkoohLhYCLFXCHFACHFXgvd/I4TYHvu3TwjRmHpTuycQiuCwWdRaqQqFQkESE6pCCDPw\nB+BCoBLYIoR4QUpZHh8jpfxOm/HfBLpekHCACIQi2FVIRqFQKIDkPPezgQNSykNSyhCwFriim/Gr\ngDWpMK43BEMRHKrVgEKhUADJifs44Gib15WxbZ0QQhQBk4A3u3j/FiHEViHE1lS3Hw2EozjsynNX\nKBQKSP2E6krgGSllNNGbUsoHpJQLpZQLCwoKUnriQCiCw6rEXaFQKCA5cT8GTGjzenxsWyJWMgQh\nGVAxd4VxWDj0AAAgAElEQVRCoWhLMuK+BZgmhJgkhLChC/gLHQcJIWYCOcB7qTUxOeLZMgqFQqFI\nQtyllBHgVuBVYDfwtJRylxDiJ0KIy9sMXQmslUO0UGNQibtCoVAYJKWGUsqXgJc6bPtRh9c/Tp1Z\nvScQiqrWAwqFQhEjbco5VVhGoVAoTpEW4h7VNEKRKHaVLaNQKBRAmoh7MKxnXjpVnrtCoVAA6SLu\nsXa/ynNXKBQKnbQQd/8Q9HJvXf8OjU89PWjnUygUit6QFuIeNMR98Dx373PP0/r2ukE7n0KhUPSG\ntIhjBAZ5oY5IdTWR48cRDsegnE+hUCh6S1p47oEUe+7hqmqiTU1dvu8v2w6ADASQmpaScyoUCkUq\nSStxT0VvmajXS9UP7qb+wYe6HOMvKzN+ln5/v8+pUCgUqSatxD0VnnvjU08jfT4CO3ciw+FO72uB\nAIHy3ZgyM/TXPl+/z6lQKE5/tECAppdeHjZP82kh7qmaUA0ePETrW29jmzwJGQwSKN/daUzgo10Q\nDuNatAgATXnuCoUC8L2/mcbHnyD08eGhNgVIE3EPhOMTqn1PhZSaRsOjj2HKyqLgzjsQVmu78Itx\nrrIyhMOBc/58QHnuCoVCJ3LiBABaS8sQW6KTHuIejHnu/Shi8m3YSGj/fjyrVmL2eLCfMZtA2Xba\nNrmUUuIv245jzhxMmZn6NuW5p5zh8lirUPSGcFzch4nDlx7iHo5gMZswm/v2caSUND71NLYpU3Cf\new4Aznnz9JTH2C8MIHzkCNH6epzz5mJyOQHQfErcO3Liru/T9K//7dO+TS/8i+O3fovIyZMptkqh\nGFgiVdUAaK2tQ2yJTnqIeyiCsx/x9nDlMaJ1dWR88gKESf9KnPPmAu0zY/wflBnvCacLUDH3jmit\nrYQPVxA6dKhP+wd2lROtr+fkPb8kOkwebxWKnpBSEqmqApS4p5RgP5fYC5aXA+CYXWJssxQUYB0/\nHv8Hek575GQNza/+G9uUKZhzcgzPXQ6TR7DhQjh2gUcbG/u2/9GjWIuKiJysofbe+5ChUCrNUygG\nhGhDAzIYBEAqcU8d/lCkX5OpgfJyzPn5mDss2u2YN4/gnj1Eamo4+ctfIUMhcr/6FQCE3Q4m07Dx\n3KWm0frOBgK7dg2pHZETMXFv6L24ay0tROvrcS9dQt7Xv0pw717q/vyXVJuoUKSc+HUPynNPKcFQ\ntM9pkFJKguW7cZTMQgjR7j3n/LkQjVL1n/+HSHU1Bbd9F9uE8QAIITA5ncNi8iTw0S6q7voBdX/4\nIw2PPTGktsQnlfriuYeOHgXAOmEC7iVLyLrqSnzvvmccU6EYrsTn5oTdrsQ9lfRnFaZwZSVaczP2\nklmd3rNPn45wu9AaG8n72lfbhW0AhNM55NkyDY8/wcn/+zM0vx/7rFmET5wY0myTeNxRBgJogUCX\n45pffwPvs8+12xY+EhP3iRMAyDhvOXCq3YNCMVwJV1WB1Yp1/Hi01q4dPs3n4/htd9D67nsDbtNp\nJ+7RqEZDc3vRCIb7Lu7BXbF4e0lJp/eE2UzuTTeSd+s3cC9d0ul9k8s1pJ67DIdpee11nIvOZux9\n9+I+ZxmEw0RraobMpraPp9GGhi7Hta5bT9PzLyCjUWNb+OhRhNuFOTcXAMvo0VjGjiWgxF2RAqSm\ntUttTnafZIicqMI6ejSmjIxuPfdoo5fIsWPQ5rofKE47cf/HO3v4wi+eJxQ+9eX4g5E+L9QRKN+N\nOT8fy6hRCd93L1uGe9nShO+ZnM4hjbkHDxxEhsO4z1mGsNmwjhsLQPjY8XbjvP/4J5W3fJXmf7/W\nTkxTjZSScFUVljFjgO5DM9H6emQgQOjjj41toSNHsU2Y2C485pw3j8Du3d0+BSgUPSEjEU7cfgfe\nXqzB0Pj3Z6i66wdJCXz8uje53d2Le5MXAFN2dtJ29JXTTtw9bjsA3tZTf+y65977CVWpaQR3707o\ntSeDGGLPPVheDkLgmDkTAMu4cQCEjx1rN86/fQdaaysNDz9C1ffuIhB7Wkk1WlMT0ufDPku3p6tJ\nValphlcfjLV4kFLqmTKxkEwc5/y5EIkQ+PDDAbFZMTLwbd5M5PgJWt56O2kHJ7h3L+EjR/Bv3dZu\nuxYMtmsxIDWNSHU1lsJCTBluNF/X4q559W6z5uys3n+IXnLaiXt2ht5DvbHllLgH+jih2l28PRlM\nQxxzD5SXYy0qwpShNzEzZ2Rgys5q57lLTSNcUUHmRReSf9t30EIhan51LzISSbk98Xi7Y5b+fXbl\nuUcbvRDzhgKxNNRobS3S78c6ob2422fMQDidKu6u6BfNL70CFgua16v3h0qCeCFd88svt9ve8NDD\nVN39QyK1dYB+7RKJYB1TqIdqW31dhn+iXt1zNyvPvTMeQ9yDhA4doun5FwgHgn0S97jX2FfP3eRy\nDlmFqgyFCO3bj6PDjck6dlw7zz1y/DgyFMI2aRKus87Cc911yGCQ8PHjHQ/Zb+JZLbapU8Bs7tJz\nj9brfxTm/HyCe/YiIxFjMtXWwXMXFguOM+d0agWhUCRLcN8+QgcO4Fl5HcLpxLfx3R73kZEI0do6\nTNnZBHfvMcKHwX37aF3/Dmgavvf0SdH4dW8ZU4jJ7QZN69Lpi3q9IITRvmQgOe3EPdttJzvix/H3\nJ6n6wQ9pXLOW66o/wG7tfVgmUF6OuaAAy6iCngcnQDhdQxZzDx7U4+32Djcm67ixhI8fM4Qw/vho\nnTRJ/z8mnnExTSWRE1VgNmMZNQqzx0O0MfGEarS+HgD3sqWxuPvhdmmQHXHOm0e0oYHw4YqU26xI\nf5pfegXhdpHxyQtwLTob35YtaD0Ux0Vq60DTyLricoTDYbTybXj0Mcw5OViLimiN3STiSQTWWMwd\nuu4vozU1YcrIQJgHfr3n007c7WVb+NHRN8jcvZPMyy7DcfnlnN1SyeQP1vfqODIcNvLb+4rJ5YRw\nOGHf94EmWL5bj7fH4ttxrOPGIVt9aLHHv9DHH+uTrWP1SU7rmDFgNhM+2l7cQ0crOfmLX+L/oKzP\nHnL4RBWWUaMQZjNmjwetq7BM3Slx1z9LOeEjRzHn52NyuTqNd87t3ApiJCClpP7Bv+LbvHmoTTlt\nidTW4tu8mYzzz8fkcOBeugTp9xP4oPtrKVKt94mxTSrGfd5yfO++R9NzzxM69DGe1atwLz+X8OHD\nhI8dI1xVhXA4MGVnnxL3LiZVo17voMTb4TQUd2fhaPa6R7Px8pvJWb0K06cvY0NmEYXbNtD8+htJ\nH6f5pZfRWlq6zIRJhrgQ9cV772/WSmBXOdbiIuNiimMZG8+Y0UMzoY8PYy2aaHgKwmLBOnYsoQ6e\nu2/jRgI7dlDzq3up+fk9hifdGyJVVVjGFAJgzvF0GZaJ1NWB1Ypl3Dis48cTKN+tT6Ym8NoBzJ5s\nbFMmjzhxD+7ZQ8sbb+J7b9NQm3La0vzqvwHI/NRFANhnz8aUnW143V0RF3fL6NFkXvwp0DS8T/8d\n2/TpuJYuxb34EyAErRvfJXJCv+6FEKfEvSWxuGvepkHJlIHTUNwds0t4YeZ5VAk99h6MaDydfyat\nU2bQ8NDDhCsrezxGpL4B7z+fxblwAY45c/psi8kZ7wzZu4yZ1vXvcPQLN1H3lwf6VMkpQyGC+/cn\nnCuwGhkzx5GaRujwYWyxkIwxZsKETp57cP8BrEVF5HzhBkKHDlF11w8I7t+fvE2aRqSqCmthTNw9\nnq4nVOvrseTmIoTAXjKL4J49hI8f7xRvb4tz3jxCBw52u7ZtutH80isARGpqh9iS05PwsWO0vP4G\nrrPPxpKfD4AwmXAvWYy/rKzblMXIyZNgtWL2eLAWFurrNwhB7k1fQAiBOScHxxmz8W18l8iJE8Z1\nfyos043nnqU89y7JdjtobNGb9ASCYTRhovnK6/Q76Tsbety/8W9rkJpGzuev75cdIua59yZjJvDh\nh9T95QEsBQW0rn+H49/+Lt7nX+hV9krwwEEIhxOKuzkvF+FwED5+nMjJk0i/H1txcbsx1okTiNbW\nGjclqWmEDh7EPmM6mZdczJjf3Ic5K4uGRx5Luogj2tCADIWMHHdzTg5aS0vCkFW0rh5zXh6gT2bL\nYBCi0S49d0C/CUtJcM+epOw53YlUV+PfuhXMZiJDWJR2uhJtbOTkPb9C2Kx4Prey3XuupUsgEsG3\neUuX+0eqT+ohxliX2Jwv3sSoH9zVzlFyLV2itwU/edK47k3u2NN8V2GZJuW5d4snw0FjLM89ENLD\nG1aPB8ecObRufLfbmHFw7z58GzaQdelnsIwe3S87euu5hyqOUPPfv8U6diyFP/spY+79FY7Zs/Gu\nWUv9Xx9KOtYdz2+3z5zR6T0hBNaxY4kcO2ZMpnb03G0xEY177+GjlchAAPu0aQCYs7LwrP4coUOH\naF2X3FyGManUxnOHxOmQkfp6owrV3mbOoGOOezubp0xG2O0Jlz5MR5pfeRVMJjIuOB/N6+1xAlBx\nCi0QoOZX96I1NVFw5x2dChRtU6ZgGTUK36auw12R6moso0/tZ8nN7fSU7zr7bLBaATp77gnEXYZC\nSJ9vUNIg4TQV9+wMO42xFgSBsO7xOu0W3EuXEK2tJbQvcThBahoNjz2GOTeXrCsu77cdvYm5Rxsa\nqPnlrzA5nRR8705MLhfWsWMouOM2sq65mta319H0j38mdd7ArnJsk4o7xdvjWMaNJXzsOOGPPwaz\nGWus2VmcuIjG4+6hWPjFNm2qMca1dAn2GdNpXLPWuFAj9fU0vfAvQhWds1birX4Nz70LcZeapodl\n8nRxN2dnYx0/XrczNl+QCGGxYJ8+3WjPnM5oPh8tb6/DtfgT2KdPBxiwlhKa30/Tiy8OWj+i4P79\nCSeIwyf0AqP+IjWN2t/9P0IfHyb/W9/EPmVKpzFCCJwLFhAoT1z5LKXUvfEuqtbjmFwuY92H+HUv\nnE4QImF/mWhTMzA4Oe5wmoq7J8NBsy9EVNOMxbHtVgvOsxYirFZaN25MuJ+/rEyf7V55HSaHo992\niF547g1PPInW3EzB9+7Ekp/X7r3sz16De/m5eJ/5By1vv93tcTS/n+C+fdhnz+5yjHXcOKL19QTK\nd2OdOAFhaV8DYM7PRzidhucePHAAU2ZmuycZIQQ5N96I1txM49qn8P7jn5z4zm00/m2N3oHygQf1\nYqQYkRMnEFYr5twc/Rw5MXHvMKmqNTVDNGp47gDu81fgWrK4k50dsc8uIXzkaNrH3Vveehvp95N5\nySVYYm2oIycHRtx9m7fQ+MSTxg1+oGn8n79R94c/dRLVxrVPUf+XB/rdv791wwYCH5SR84UbcC6Y\n3+U45/y5EA4nbJGtNTUhAwGsSTzZZ15yMbbJkw0HSphMCJczoeceL2AyqZh713jcdjQpafGF8MfE\n3WGzYHI6cS5YgG/T+wlj2M0vvYI5NxfXksUpsePUgh2nPPfAhx9Rc99v2v1yA7t343v3XTIvvwxb\n0cROxxFCkPvlL+GYM4f6Bx8iuP9Al+cMfPgRRKNGemAi4j1mQgcOdArJxM9nnTDByHUP7j+AbdrU\nTi2PbZOKybjgfFpeex3v35/BOW8ehff8nMxPX0LruvUc/8539eZfoZCRKROPUZo8ush39NyNAqa8\nU+Ke9elLyP/G17v8PHHiaavB3ekbdw/u3Ufz/76IfcYM7FMmG2sMDFTcPVqrT9aG2zR8Gyi0YJDg\ngQPIYLBdSb/m8xmrnHXXbK7H4/t8NP5tLbZpU8m46MJux9pnzUI4HAmb0hmZMj147qBXYxf+/P+2\ncxa76i+jNQ1edSqcruLepgVB0BB3PdXPtWwJWlNTpxLjUEUFwV27yPzURT16iMmSKCzj/+AD/Fu2\nUPPfv0FGIsholIZHHsOcn0/W5Zd1eSxhsZD/nf8PYbfT8trrXY7zl5UhXC7sM6Z3OSaeMQN0mkw1\ntk+cQOjoEbSWFiLHjhnx9o5kr7yOjIsuZNSPf0T+t7+FrbiYnM9fr88XlMyicc1ajt92B8H9B7DE\n4o4Q650hRKc/1kisgMnSxnNPFtvkeNw9/UIzkZoaau//HdX/58cAeK7/HKCngWKxDFjGTKROv9lG\nBqFnfmjfPr0bYiyFMI5vy1aITbxH+iHu3mefQ/N6ybnxC4aT0RXCYsExZ07Cuo542wFLYd/m5Ewu\nd+KwjNF6QHnuXWL0l2kNGhOq8fYDztJShNvVKTTT/PIrCLsd9wXnp8wOYbEgrNZ2LQgitXUIu53g\nrnLq/vwALW+8SfjIEXKuX43Jbu/2eCaXC9fZXVfQSSkJbN+O88w53d6gLKNGQSyvPZHnDno6pGz1\nGRkD9qlTE44zZ2SQe/NNRnMyY/+xYyi443ZG3f0DTE4HWlNTu5i5MJsxZWV19txjBUzm3PahqWQQ\nFgv2mTOMthHpQvDAAU7cfif+bR+Qdc3VjPnNfcbNVphMWPLzByzmbnjuVQPvuQfKd+uTxJ+8gMDO\nnUZ4zbdxI8Jm0+2p75u4h48fp/mll3GftzxhnD0RznlzidbXd6rWjlTHxL2gb5XrXXnu0VjTsGEV\nlhFCXCyE2CuEOCCEuKuLMdcKIcqFELuEEH9LrZntaeu5B9rE3AGE1Ypr0SL8W7Yacb2o10vrho24\nzz0Hc6zJVqoQLifSf+ouHa2rxT5rJtnXXYtvwwYaHn0M++wSnIvOTup43VXQhQ8fJtrQiGPevO5t\nslh0L9pkwpogDASnJlVb3nwLhND7wfQBx5wzKLznFxTccTuZn/l0u/fMOZ1z3aN1dWCxYMrqW28N\ne0kJ4aPpE3ePVFdT86tfY8rOYsx99+L5j892mg+yFBQMWFgm3vwqkoKwTOTkSbRuFjUPlpdjmzyZ\njE9eANEovvc3E230EvjwI9yxhVn6EpbREyWeQNhseFZel/R+8cnQjsVxkeqTmHNzjRtObzG53cgE\nee6a14uw21My35eUHT0NEEKYgT8AlwAlwCohREmHMdOA7wNLpZSzgW8PgK0G2Rmxtr8tQQKhCDar\nGZPpVLzYfe45yECAqru+j2/rVj3MEYmQecnFKbfF5HR18twt+flkXXkFGRecD2YzOV+4oVM8uyvs\ns0sweTwJK+j8H5SBEDjnlvZ8nGlTsU2ZgqmLCzSeDhk6cADrhPFGWmdfECYTzgXzMXdohmT2dK5S\n1dMgc3p8bO4KI+6eBt57tLmZk/f8CjSNUXd9r0tP0VyQT6Q29eIupdRvtug3mf5kzMhIhKq7/5Oq\nH/5nwhuvFggQPHAQR8ksrBMnYh0/Dt/Gd/V0RCnJuPBChNXaa889sHsP1T/8TwI7dpD9H5/tVTzb\nnJODdVIxgU7i3j4NsreY3K4uJ1QHK94OyXnuZwMHpJSHpJQhYC1wRYcxXwb+IKVsAJBSnkytme3J\ncNgwm4ThuTs6LNThmDmTgu9/D8wWan/933j/8U8c8+Z2m2rXV0wuJ1rMc9dCIbSmJsx5eXq2yZe+\nyPg//xHbxMTecyKEyYR7ceIKOn/ZdmyTJyd1geTefBOj7v5+13ZnZBgZK7YuQjL9xezJSRiWsfQh\nJBPHNmmSPhEWi7uHj5/A+9zzaLGV55Oh5e11SVUy95VIXR3Nr/67k1hqoRCNa9ZS/8ij1D/yKCd/\n9nMitbUU3HFbt9empaAAzdvU5WcM7N5tTEj2Bq2lBRkMYhkzBhkM9msy0799B1pzM5Hqk9Tc++tO\ntgb37YdoFPvsEoQQuJYuJbhnD82vvIK1qAjbhPGYc3KStkGGw9Te/ztO/tdPiDZ6ybv1631y3pzz\n5hHct59oc7OxLXKyul81MCa3O2H7Aa2pCdMgxdshOXEfB7QNSlXGtrVlOjBdCLFRCLFJCJHwWxZC\n3CKE2CqE2FrTj8dMk0mQ7bbjbQ3oC3XYO8efnaWljPnlL8i56Uas48aSffVVfT5fdwinCxlLhYzG\nHnGNUuc2vSZ6g2tZ5wq6aFMToYMHcc7vPiRj2GWz9fj4F68I7Woytb+YczxoXm87kYu2KWDqC8Ji\nwT5jBoGdH9Lw2BOcuONOvGufwpdEZTLok9/1f3mAxjVr+2xDt8dvaeHkz35BwyOPGks4xvFv2UrT\n8y/QumEDvo3vojU1k//Nb2Cf0bkYrS3xrI2u4u4Njz1B3V8e6HXDt/j16phzBnCqH39f8G3ciCkz\nk7xvfZPQgYPU/f4P7X7vwfJyMJmMz+qOZaxFqqqNJSzNublEG+qTOp+/bDu+9zaRdflljPnNfbiX\nLUv66bgtznnzQEoCO3YCekZPtKExqUyZrjC53chwuFNa53D03JPBAkwDzgNWAQ8KITwdB0kpH5BS\nLpRSLizo42RFnOwMvQVBIBTF0UW7X2GxkPmpixjz63sHTMB0z10Py0Tr9Mkpc37fPVPQs0IshaPb\nTQr7t28HKY04YSqIx93t0wbKc/eAlEaHSimlHpbJ67u4gx6aiVRV0fzKK2SctxxLYWGPjaDihCoq\nQEr823e089ZSgQyHqbnvv/VsC7O5UyzXX1aGKTOT8Q8+wPi/PsC4P/5er3LsAUuB7iwkirtrLS2E\nKyrQvF4iHXr0+8vKqP39H7tcojASu14dZ+g1E12lQ0bqG6i59z6C+/YlfF/z+/Fv+wDX4k/gXvwJ\ncm74PP4tW2l4/AnjhhMo341tymTD4bCMHm0UzcVTk/Vmc8l57oHycoTNRva1/9FjokJ32KZMxpSV\nZVS2x+sJ+uu5Q+f6l6i3adAmUyE5cT8GtK0LHx/b1pZK4AUpZVhK+TGwD13sBwxPhgNvPCzTx8Wx\nU0HbmHt8csqSl9+vYxqPrbvKCR87RrS5Gf/WbZg8HqxdpDb2hYzzlpN11ZVGJ8lUYxQyxUIzWnMz\nhMN9SoNsi3v5uWR86iIK7/k5uV/+Eu5zlhHcs8f4/rsjHF8eLRrF/37fWukmik1LTaPuj38iuHsP\neV//Ko7ZJe1Wj5KaRmDHDhxzS3s932AUMiVIhwzs2QNxAe3wpND0wv/i27CBuv/3+4RdSOOeu336\ndITVmnBSVfP7qfnVr/Bv20bdXx5MWD/i37oNGQoZHnjmJReT+ZlP0/LKqzS/+BJaIEDo4MFOvZA8\nq1bhWf0540nXnJtLtL4hqSeQYHk59hnT+53WLEwmMi+5mEBZGU3/fLZXOe5dkagFgdQ0PWQ7zDz3\nLcA0IcQkIYQNWAm80GHMc+heO0KIfPQwzaEU2tkJT4bdiLnbh1DcRZuYe6S2FoQwqjT7g3vpEpCS\nE7fdwbEvfwX/5i04583t80RkIqzjxuG57tqUHrMtRguC2KRqfJGOeNOw/hw396YbsRUVAbFGUFIa\nK+N0R+jjw5iys7GMHZu0t9+Whsee4MTtd3byhptffAnfe5vwfG4V7iVLcM6bR+TECSPFMLT/AFpz\nix4G6CWm7GywWhN67sFdu/XK4BxPu0lmrbWV4N69WCdMwL/tAxoefaxzPndtLVit+vdRWEikqn2u\nu4xEqP3t/YSPHCXzM58mcuwYzf9+rZMNrRs3Ys7Px9bm6diz+nO4PrGIxv95ksYn/kePt3cQd0fJ\nLLIuu9R4bc7JMfqvdEe0qYnwkaOdjtdXsq68Ave55+L9+zM0/+t/Afo5odpZ3LWWFpByeIm7lDIC\n3Aq8CuwGnpZS7hJC/EQIEW/Q8ipQJ4QoB94C7pBS9uxG9YNstyOW5x7BOaSeuxPp8xuZB+acnJQU\nSVnHjiX/tu+Qc+MX9H833Yjn2v9IgcWDh7lDlaqR497PsExHrIWF2KZM6STWoYqKTl526PDH2CZP\nwr10SdLefpzgwYM0v/IKkePHaXr+lH8TqW/QJ+3nzyMzJlbxdNX4RKe/rAxMJpylZ/b683WX6x7Y\nXY5t+jTss88gsLvcEHD/zg9B08j90s1kXnYpLa+9bghXnGhtHZbY5L9lTGG7sIyUkvq/Pkxgx05y\nv/wlPNevxlFaivfvzxjFOKALbWDnh7iXLmnnJAiTibyvfw37jBm0vPEmmM3dFt4BhlPUU2gm3hm0\nr8tjdkQIQe4tX8Ix5wyCe/cinM5+LYOXqDOk0XpgOIk7gJTyJSnldCnlFCnlz2LbfiSlfCH2s5RS\nfldKWSKlnCOlHJjZqjZ4MhyEwlEaWwJD6rmbXE6QEhkMEqmt7bdX2hbXWWeRefGn9H+fughzTv+f\nCAYTs0e/kON/rPFqyP6GZRLhWrrEWBkH9KK1qu99n5bYYg2gZ6uEK49hKy7ulbcPGEusmbKycJ51\nFk3/+6LxCN+4Zg0yEiHnhs8bk3rWwtFYxo4hsF0PzfjLtmOfMb1PE+ygx907eu7RlhbCFUdwlJTg\nmF2C5m0iEvv8gbIyTBkZ2KZNw7NqJc5FZ+tN4NrkoUfqao35IWthoZ4OGQvfBHfvofXtt8m66koy\nVpynZ3994fPIUIjGtU8Zx/Bteh80Tf8+OyBsNvLvuA3L2LHYZ87scYI/fn1HekiHDJTvRtjt2KZM\n7nZcb9ArxL+tZ+5MnNinydk4CT33WAHTYPVyh9O0QhVO5bo3NAeM1gNDgckZu0v7fLon1M/J1HRC\n2GyY3G7Cx/Q1XaP19WA2D4j30nZlHN/mzTQ8/gQAvjY9TMJHjoCmYZs0qUtvvytaN2wgtP8Ans+t\nIucmvby94X+e1FtIv7OBrM982mj7Gsc5b56+ytTx44QrKvoUkomjFzK1j7kHY/F2e0mJkf8fKN+N\n1DT823fgKD1Tb2RlMpF54YV6P/yDB439o7GaDIh1NYxGjYrV1g0bEHY7WVeeynq2jh1L5iUX0/r2\nOuoeeJD6hx+h+cWXsE6Y0GW6rzkjg8Jf/IyCO27r8TOac/Sbfo+e+65yfZ4gRW1E4phcLgp/+l96\nGnW/jhMX9zbFjfHWA57B89yHzuXtJ/EqVaBTnvtgIozmYT4idXU4z1o4ZLYMRxylZ+J79z0iNTUI\nk1kPWw1AjD++Mk7LG28ifT5sU6dgmzKFltdeR/P5MLlcbfrbFwO6t9/4+BOEjx1r14+nI0ZDqqlT\ncU/tQTIAAAxXSURBVJ+zDGEykXX1VXjXrCV08BDmnByyrrqy037OefNofvElGp54EqDHyuJuP19B\nAVpTE1ogYHjAwV3lCKsV+9QpYLFgzsvTq0AnTUJramp3M7FNmQxCENy3H2dpKTISIdrYaDxpxvsC\nhU9UYc7Nxf/+ZpxnndUpEyX76qsI7tuPf0s8TVfg6aF9drLZLEZYpr7rdMhoUxPho0dT1vyvI8Jm\no+8+u44po7PnPtgdIeE09tw97lMXTKI898Ei7rmHq6r1TJAUhmXSgbxbv0HuV79CpKaW4N69/cpx\n7wnX0iVoXi/mvFwK7rgd16KzIRrVO2miLxZuysjAHPNWDW9//TvdHrfp+RfQGhsNjx30TpaW0aOJ\n1tfjWf25hCEH+8wZCKeTQFkZ5vx8rOO7voH0RKKMmUD5bmwz9EwXIQSO2SUEynfj/+ADffH0NpXM\nJqcT64QJhA7oHUej9fUgpeG5W2P9yCNVVfh37ERrbTWyX9picrko/MmP9XTOBx9g/IN/IeP8FX3+\nXO2OHXvS685zj3cEdcxOTbx9IBAWC8Ju7xCW8epPrX0My/WFtPDchzzmzqlVjeLCodARJhMZ5y3H\ntehsml/9t74wxwDhWryYyIkq3CtWYM7KwuR2I9wu/GVluBadTfjwYWyTio14qjknR7fr5VfIuPDC\nhCE1ze+n+d+v6QtntGlIJaxW8v+/b+LfsTNhvBnadB7cvFnPdOpHHNcyShf3aE0NTBivx9uPHCH7\nPz5rjLGXzKJ1/Tu0vPEm9unTOvVRsk+bSuumTfp6t0bBnf6ZTdlZeo//EycI7t2LKTPTKG4aTHqq\nUg2Ul+vx9smpi7cPBCaXq31YpqkJc1bmgGWmJbRh0M6UYrLaeu5DGpaJee4xcVcx98SYnE6yr7wC\n18IFA3cOux3PqpVYY61ahdmM88wz8ZdtR4bDhI4cxVrcvkum53OfAylpfPLJhMdsfXudvnBGh6Zo\noBebZV91ZbeiHa8oTrayuCssHfq6B3fvjsXbZxlj4tkjWlNTwhCQbdpUZKuPyIkTRmzdnHeqmto6\nppDQx4eNgqRUx7STwZyb021/meCu1OS3DzQdO0NGvd5BzZSB01jcrRYzGU69KdbQTqjGPXe9V4ny\n3IcXznnz0LxefeH0SMSIt8exjCog8/LL8L23qdP6rFLTaH7lVWzTp3fZErkn3OcsI//27+LoZnGV\nZDBlZyOsVgIffYRv0/u0rt+AsNna2WUZNcq4/hJN3sartIP79xuZS22rqS2FhYT27WtXkDTYdOe5\nR71ewpWV3a5CNlzoKO6at2lQM2XgNBZ3gOyY9+6wWYfMhviCHeHjx/V2noMYU1P0jGNuKQhB03PP\nA3QSd4Csyy/DnJ+vF/q0qeT0f/ABkepqsj7d926iwmzGtXBhv0IyEF89azz+LVup/e39+LdswT57\ndicP1jl/HpaxYxIuNm4ZMwbhdhHaf4BobS2mrKx2XUON9W87FCQNJubcXKKNjQmrgFvX64u1x9sl\nDGeE24XmG1rPfXg/2/SAJ8PBsdrmIfXcRXwiLRrFXFjY7z9iRWoxZ2VhmzqF0P4DCKczYc8Qk91O\nzvWrqf3t/TQ9+xxZV1+FMJn0ZRnz83GeddYQWN6ZUT+82/C4IXGJfM4Nn0eGwwmvQ2EyYZ86leD+\nA5hzcjqFEOOpnB0LkgYTc04OaJo+Md6mriPa2Ij3n8/hmDcv6cU4hhKT220sAiKl1FsPZClxT5p4\nrvuQth8wmRBOJ9LvV/H2YYpz3jxC+w9gKy7qUrSci87GuXAB3mf+gW/bNjIuuIBgeTme1Z9DmIfO\neWiLyeXCFntS7AphsXQbj7ZNnUrTP59F8/k6rdJlnzUTa3ER7hXnpcLcPtG2SrWtuDeuWYsMhci5\n4fqhMq1XtA3LyEAAGQph9qiwTNLEM2aGsnEYnIq7p7I6VZE64vFnW3HiJQdBD3vkf/c75N36DTRv\nEw1/fQhht5MxhEI3ENinTQMpidbWdmoDYcnPZ8w9v+hUjDWYJKpSDe4/QOu69XqhWCx0NNwxud1I\nv1/PTIqtT2tSnnvyeNy6uA9lbxnQ0yGj9af6uCuGF9biIrKuuVrPa+8GYTLhXrYU51kLaXn135hz\ncjCleFnGocbeZjnF4Xi9xsU9Pqmqt314FHOOJ2Gh2HAlPvcWqaqm9ne/x5SZMehzBae1uOdl6x6z\n2zF0E6oAIu65q7DMsEQIgadNPnhPmOx2si6/bAAtGjpMGRlYxo4lcvz4sAwjmrOzQQijSrV1/XpC\nBw+R942v92spyMEmnmhR86t7idbVMeqHdw96geNpLe7LS4vIz3aRl919HHKgif8i+9vHXfH/t3ev\nIVLVYRzHvz9md9VZwVlTTFdTw6VYQlMk1pQwM1CL7IWR0kVC6E2QSRBGr3oZRDcIQbSyCI1USnwR\nlAW9ytIKWy+12sX7JVJXuqibTy/Of2NYXS/rnD1z/vN8YNj5n5nlPA/P7LMz//Ofc1x/GNAyga7D\nh/9f415NVChQKA3h35OnktM+rF1HQ0sLxRnTsw7tmnSfgqDr2DGGLVt6xTNiphJDv++xghrqC0xu\nyW5+sFv3O4pqfCfkXE8DJ05EDQ3U3dj3qw2lqdCUXG7v9IaNXOg8w9AnFuduFVrd8GQlU+mxR6/q\nalupxJDJXiOjYjFcpCO986Y4VynFO6cxaNLEqj2eUGhq4mxHB/+076Tx7plVf6qBS2kYexPNq1Ze\ndAqI/uTNvQIGtrZif/2N6rOd+3fuakhCVdrYIVkOeaGzExWLlBY+nHU4fZZlYwdv7hXROGM6jTmb\nE3SuWnWvmCk9tKDfv7IfE2/uzrmqUmxrw86eZfC9s7MOJde8uTvnqkr9qJGUFi3MOozcy/VqGeec\nc5fmzd055yLkzd055yLkzd055yLkzd055yLkzd055yLkzd055yLkzd055yIkM8tmx9IJ4Lc+/vow\n4PcKhpMXtZh3LeYMtZl3LeYM1573WDMbfqUnZdbcr4ekbWY2Nes4+lst5l2LOUNt5l2LOUN6efu0\njHPORcibu3PORSivzX1l1gFkpBbzrsWcoTbzrsWcIaW8cznn7pxz7vLy+s7dOefcZeSuuUuaI+lH\nSXslLc86njRIGiPpC0m7JO2UtDRsHyrpU0kd4WdT1rFWmqSCpO8kbQ7j8ZK2hnp/IKkh6xgrTVJJ\n0npJeyTtljStRmq9LLy+2yWtlTQwtnpLekvScUntZdsuWVsl3gi575A05Xr2navmLqkAvAnMBVqB\nRZJas40qFV3As2bWCrQBT4U8lwNbzKwF2BLGsVkK7C4bvwS8amYTgJPAkkyiStfrwCdmdiswiST/\nqGstqRl4GphqZrcBBWAh8dX7HWBOj2291XYu0BJuTwIrrmfHuWruwB3AXjP72czOAeuA+RnHVHFm\ndsTMvg33z5D8sTeT5LomPG0N8GA2EaZD0mjgPmBVGAuYBawPT4kx5yHAXcBqADM7Z2aniLzWQR0w\nSFIdUASOEFm9zexL4I8em3ur7XzgXUt8BZQkjezrvvPW3JuBA2Xjg2FbtCSNAyYDW4ERZnYkPHQU\nGJFRWGl5DXgOuBDGNwCnzKwrjGOs93jgBPB2mI5aJamRyGttZoeAl4H9JE39NLCd+OsNvde2ov0t\nb829pkgaDGwAnjGzzvLHLFnmFM1SJ0n3A8fNbHvWsfSzOmAKsMLMJgN/0mMKJrZaA4R55vkk/9xG\nAY1cPH0RvTRrm7fmfggYUzYeHbZFR1I9SWN/38w2hs3Huj+mhZ/Hs4ovBdOBByT9SjLdNotkLroU\nPrZDnPU+CBw0s61hvJ6k2cdca4DZwC9mdsLMzgMbSV4Dsdcbeq9tRftb3pr7N0BLOKLeQHIAZlPG\nMVVcmGteDew2s1fKHtoELA73FwMf93dsaTGz581stJmNI6nr52b2CPAFsCA8LaqcAczsKHBA0i1h\n0z3ALiKudbAfaJNUDK/37ryjrnfQW203AY+HVTNtwOmy6ZtrZ2a5ugHzgJ+AfcALWceTUo4zSD6q\n7QC+D7d5JHPQW4AO4DNgaNaxppT/TGBzuH8z8DWwF/gQGJB1fCnkezuwLdT7I6CpFmoNvAjsAdqB\n94ABsdUbWEtyTOE8yae0Jb3VFhDJasB9wA8kK4n6vG//hqpzzkUob9MyzjnnroI3d+eci5A3d+ec\ni5A3d+eci5A3d+eci5A3d+eci5A3d+eci5A3d+eci9B/MxqI4naCRgMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee3c5842b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plt.plot(range(len(best_losses)),best_aug_losses, label ='best losses')\n",
    "# plt.plot(range(len(eporch_losses)),eporch_aug_losses, label ='eporch losses' )\n",
    "plt.plot(range(len(accs_train)),accs_train, label ='Train Accuracy' )\n",
    "plt.plot(range(len(accs_val)),accs_val,label ='Val Accuracy' )\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that CNN is much better at fitting the training data correctly when compared to Linear SVM or LR. However, the testing accuracy is around 70%, with the best test accuracy around 80%. This does show that we are doing much better than with the baseline models, but there could be some overfitting in this case.  \n",
    "\n",
    "Below we are adding the augmented data in order to see if this will improve our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train accuracy: 70.0000%, test accuracy: 54.5455%, best loss: 0.605495\n"
     ]
    }
   ],
   "source": [
    "# train_aug_data =  DataAugSet(np.arange(0,2130), train_labels[:2130])\n",
    "best_aug_losses =[]\n",
    "eporch_aug_losses=[]\n",
    "accs_aug_train =[]\n",
    "accs_aug_val =[]\n",
    "epoch_aug_stop=0\n",
    "\n",
    "y_test = train_labels[2240:]\n",
    "test_data = DataSet(np.arange(2240,len(train_labels)), y_test)\n",
    "train_aug_data =  DataAugSet(np.arange(0,2240), train_labels[:2240])\n",
    "X_val, y_val = test_data.next_batch(55)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 40\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 5\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 120\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(train_aug_data.num_examples // batch_size):\n",
    "\n",
    "            \n",
    "            X_batch, y_batch = train_aug_data.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            if iteration % check_interval == 0:\n",
    "                loss_aug_val = loss.eval(feed_dict={X: X_val, y:y_val})\n",
    "                if loss_aug_val < best_loss_val:\n",
    "                    best_loss_val = loss_aug_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "\n",
    "\n",
    "        acc_aug_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "#         loss_aug_val = loss.eval(feed_dict={X: X_val, y:y_val})\n",
    "        acc_aug_val = accuracy.eval(feed_dict={X: X_val, y: y_val})\n",
    "        \n",
    "        print(\"Epoch {}, train accuracy: {:.4f}%, test accuracy: {:.4f}%, best loss: {:.6f}\".format(\n",
    "                  epoch, acc_aug_train * 100, acc_aug_val * 100, best_loss_val))\n",
    "#         accs_aug_train.append(acc_aug_train)\n",
    "#         accs_aug_val.append(acc_aug_val)\n",
    "#         best_aug_losses.append(best_loss_val)\n",
    "#         eporch_aug_losses.append(loss_aug_val)\n",
    "\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            epoch_stop = epoch\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_isd_model102\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nT/SNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee3cbb99e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plt.plot(range(len(best_losses)),best_losses, label ='best losses')\n",
    "# plt.plot(range(len(eporch_losses)),eporch_losses, label ='eporch losses' )\n",
    "plt.plot(range(len(accs_train)),accs_aug_train, label ='Train Accuracy' )\n",
    "plt.plot(range(len(accs_val)),accs_aug_val,label ='Val Accuracy' )\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen form the graph, our training accuracy decreased with the addition of augmented data and increased dropout rate. This means we managed to reduce some of the overfitting by adding more images which the model has to adjust for, as well as by increasing the number of coefficients randomly set to zero during training. However, we didn't see any consistent improvement on the test data accuracy, which shows that our model still needs to be further adjusted. \n",
    "\n",
    "The below code shows how we tried to evaluate our performance on the test dataset. We used the different CNN models we generated previously and for which we saved our parameters. We also generate the labels being assigned to the data at the time of the run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with data aug: 0.887499998013\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "test_data = DataSet(np.arange(2050,len(train_labels)), train_labels[2050:])\n",
    "test_batch_size = 10\n",
    "acc_test =[]\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"./my_isd_model101\")\n",
    "    for iteration in range(test_data.num_examples // test_batch_size):\n",
    "        X_test, y_test = test_data.next_batch(test_batch_size)\n",
    "        acc_test.append(accuracy.eval(feed_dict={X: X_test, y:y_test}))\n",
    "        #print(\"probability\", Y_proba.eval(feed_dict={X: X_test}))\n",
    "        #print(\"actual\", y_test)\n",
    "\n",
    "       \n",
    "\n",
    "print(\"Test accuracy with data aug:\", sum(acc_test)/len(acc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with data aug: 0.836363646117\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "test_data = DataSet(np.arange(2240,len(train_labels)), train_labels[2240:])\n",
    "test_batch_size = 5\n",
    "acc_test =[]\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"./my_isd_model2\")\n",
    "    for iteration in range(test_data.num_examples // test_batch_size):\n",
    "        X_test, y_test = test_data.next_batch(test_batch_size)\n",
    "        acc_test.append(accuracy.eval(feed_dict={X: X_test, y:y_test}))\n",
    "        #print(\"probability\", Y_proba.eval(feed_dict={X: X_test}))\n",
    "        #print(\"actual\", y_test)\n",
    "\n",
    "       \n",
    "\n",
    "print(\"Test accuracy with data aug:\", sum(acc_test)/len(acc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.924999994536\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "test_data = DataSet(np.arange(2050,len(train_labels)), train_labels[2050:])\n",
    "test_batch_size = 10\n",
    "acc_test =[]\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"./my_isd_model2\")\n",
    "    for iteration in range(test_data.num_examples // test_batch_size):\n",
    "        X_test, y_test = test_data.next_batch(test_batch_size)\n",
    "        acc_test.append(accuracy.eval(feed_dict={X: X_test, y:y_test}))\n",
    "        #print(\"probability\", Y_proba.eval(feed_dict={X: X_test}))\n",
    "        #print(\"actual\", y_test)\n",
    "\n",
    "       \n",
    "\n",
    "print(\"Test accuracy:\", sum(acc_test)/len(acc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction for test set\n",
    "pred_data = DataSet(np.arange(0,1531), None)\n",
    "pred_batch_size = 50\n",
    "prediction_labels =[]\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"./my_isd_model101\")\n",
    "    for iteration in range(pred_data.num_examples // pred_batch_size+1):\n",
    "        X_pred = pred_data.next_pred_batch(pred_batch_size)\n",
    "        prediction_labels.append(Y_proba.eval(feed_dict={X: X_pred}))\n",
    "\n",
    "\n",
    "#print(\"labels:\", prediction_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in prediction_labels for item in sublist]\n",
    "final_list=[]\n",
    "for i in range(len(flat_list)):\n",
    "    if(flat_list[i][0]>flat_list[i][1]):\n",
    "        final_list.append([i+1,0])\n",
    "    else: final_list.append([i+1,1])\n",
    "\n",
    "np.savetxt(\"output_aug14_2.csv\", final_list, delimiter=\",\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Kaggle Results\n",
    "\n",
    "With our best CNN model configuration, which included data augmentation and a high dropout rate during training, we managed to reach 224th place in the Kaggle competition, with a submission score of 0.82862. This was an improvement on our previous submission of 0.75753, which didn't include these methods for regularization. This shows that we managed to reduce overfitting in a way that had an effect on our prediction accuracy on unseen data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Development\n",
    "\n",
    "If given more time and resources, we could improve our model and accuracy in a number of ways. First, if we could get the hardware required (with a lot of memory and high-peformance GPUs), we would be able to feed the complete images into our CNN, which should give it a lot more information to work with and hopefully improve its accuracy. Second, we could also test more layer setups for our CNN, possibly adding more convolutional layers and working with bigger intermediate dimensions. Third, we could generate even more augmented images and fit models using a bigger training set. Fourth, we could employ feature engineering for image data in order to improve the performance of our CNNs further. Fifth, we could work on developing non-linear SVM algorithms (not currently available in TensorFlow) and see if SVMs can be made to better process image data, since they require less hardware resources to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this project we attempted to build a classifier that can work out whether a certain invasive species of plant (Hydrangea) is present in photos of wildlife areas in Brazil. We started by trying to use the Logistic Regression, single-layer NN, and Linear SVM algorithms, although they proved inadequate for the complexity of the input data. We then moved on to using CNNs that are better suited to working with image data, managing to achieve a much better performance. We tried to adjust for overfitting and improve our performance further by using data augmentation and a higher dropout rate to generate more samples and regularize. This improved our accuracy on unseen data, as noted by our Kaggle results before and after the change. Finally, we identified ways we could improve this projecct in the future, so we could one day hope to better understand the spread of invasive species around the world. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
